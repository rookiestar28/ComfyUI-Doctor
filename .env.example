# ComfyUI-Doctor Environment Variables
# Copy this file to .env and customize as needed

# ==============================================
# Local LLM Service URLs (Cross-Platform Support)
# ==============================================
# Override default URLs to prevent conflicts between:
# - Windows native vs WSL2 Ollama instances
# - Docker containers vs host services
# - Custom network configurations

# Ollama (default: http://127.0.0.1:11434)
# OLLAMA_BASE_URL=http://127.0.0.1:11434
# For WSL2 access from Windows: OLLAMA_BASE_URL=http://localhost:11434
# For Docker: OLLAMA_BASE_URL=http://host.docker.internal:11434

# LMStudio (default: http://localhost:1234/v1)
# LMSTUDIO_BASE_URL=http://localhost:1234/v1

# ==============================================
# General LLM Provider Settings (Optional)
# ==============================================
# These override ComfyUI settings for all users

# Default LLM Provider Base URL
# DOCTOR_LLM_BASE_URL=https://api.openai.com/v1

# Default LLM API Key
# DOCTOR_LLM_API_KEY=your-api-key-here

# Default LLM Model
# DOCTOR_LLM_MODEL=gpt-4o
