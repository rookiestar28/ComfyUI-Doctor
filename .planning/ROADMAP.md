# ComfyUI-Doctor Architecture & Extension Roadmap

[ç¹é«”ä¸­æ–‡](#comfyui-doctor-å°ˆæ¡ˆæ¶æ§‹èˆ‡æ“´å±•è¦åŠƒ) | English

## 1. Architecture

### 1.1 Core Module Structure

```mermaid
graph TD
    A[prestartup_script.py] -->|Early Hook| B[__init__.py]
    B --> C[logger.py]
    B --> D[analyzer.py]
    B --> E[i18n.py]
    B --> F[config.py]
    B --> G[nodes.py]
    
    C --> H[AsyncFileWriter]
    C --> I[SmartLogger]
    
    D --> J[ErrorAnalyzer]
    D --> K[NodeContext]
    
    B --> L[API Endpoints]
    L --> M[/debugger/last_analysis]
    L --> N[/debugger/history]
    L --> O[/debugger/set_language]
    L --> P[/doctor/analyze]
    L --> Q[/doctor/verify_key]
    L --> R[/doctor/list_models]
    
    S[web/doctor.js] --> T[Settings Registration]
    U[web/doctor_ui.js] --> V[Sidebar Panel]
    U --> W[Error Cards]
    U --> X[AI Analysis]
    Y[web/doctor_api.js] --> Z[Fetch Wrapper]
```

### 1.2 Module Overview

| Module | Lines | Function |
|--------|-------|----------|
| `prestartup_script.py` | 102 | Earliest log interception hook (before custom_nodes load) |
| `__init__.py` | 477 | Main entry: full Logger install, 6 API endpoints, LLM integration |
| `logger.py` | 339 | Smart logger: async writes, real-time error analysis, history |
| `analyzer.py` | 271 | Error analyzer: 20+ error patterns, node context extraction |
| `i18n.py` | 190 | Internationalization: 4 languages (en, zh_TW, zh_CN, ja) |
| `config.py` | 65 | Config management: dataclass + JSON persistence |
| `nodes.py` | 179 | Smart Debug Node: deep data inspection |
| `doctor.js` | 528 | ComfyUI settings panel integration |
| `doctor_ui.js` | 778 | Sidebar UI, error cards, AI analysis trigger |
| `doctor_api.js` | 114 | API wrapper layer |

---

## 2. Robustness Assessment

### 2.1 Strengths âœ…

1. **Two-phase logging system** - `prestartup_script.py` ensures capture before all custom_nodes load
2. **Async I/O** - `AsyncFileWriter` uses background thread + batch writes, non-blocking
3. **Thread safety** - `threading.Lock` protects traceback buffer, `weakref.finalize` ensures cleanup
4. **Complete error analysis pipeline** - 20+ predefined patterns, regex LRU cache, node context extraction
5. **LLM integration** - Supports OpenAI/DeepSeek/Ollama/LMStudio, auto-detects local LLMs
6. **Frontend integration** - Native ComfyUI Settings API, WebSocket `execution_error` subscription
7. **Internationalization** - 4 languages, extensible `SUGGESTIONS` structure

### 2.2 Potential Issues âš ï¸ â†’ âœ… ALL FIXED

- [x] **P1**: Overly broad `except Exception: pass` statements â†’ *Fixed in Phase 1 (R1)*
- [x] **P2**: Race conditions on `_analysis_history` deque and `SmartLogger._instances` â†’ *Fixed in Phase 1 (R2)*
- [x] **P3**: Resource leak risks with `aiohttp.ClientSession` per-request creation â†’ *Fixed in Phase 2 (R3)*
- [x] **P4**: No XSS protection on AI analysis results in frontend â†’ *Fixed in Phase 1 (R4)*
- [x] **P5**: Missing API endpoint tests and frontend tests â†’ *Fixed in Phase 1 (T1) + Phase 2*

---

## 3. Extension Todo-List

### 3.1 Features

- [x] **F1**: Error history persistence (SQLite/JSON) - ğŸŸ¡ Medium âœ… *Completed (Phase 2)*
- [ ] **F2**: Hot-reload error patterns from external JSON/YAML - ğŸŸ¢ Low
- [x] **F3**: Workflow context capture on error - ğŸ”´ High âœ… *Completed (Phase 2)*
- [ ] **F4**: Error statistics dashboard - ğŸŸ¡ Medium âš ï¸ *Use dev branch*
- [ ] **F5**: Node health scoring - ğŸŸ¢ Low
- [ ] **F6**: Multi-LLM provider quick switch - ğŸŸ¡ Medium âš ï¸ *Use dev branch*
- [ ] **F7**: One-click auto-fix for specific errors - ğŸŸ¢ Low

### 3.2 Robustness

- [x] **R1**: Comprehensive error handling refactor - ğŸ”´ High âœ… *Completed*
- [x] **R2**: Thread safety hardening - ğŸ”´ High âœ… *Completed*
- [x] **R3**: aiohttp session reuse - ğŸŸ¡ Medium âœ… *Completed (Phase 2)*
- [x] **R4**: XSS protection - ğŸ”´ High âœ… *Completed*
- [ ] **R5**: Frontend error boundaries - ğŸŸ¡ Medium âš ï¸ *Use dev branch*

### 3.3 Testing

- [x] **T1**: API endpoint unit tests - ğŸ”´ High âœ… *Completed*
- [ ] **T2**: Frontend interaction tests (Playwright) - ğŸŸ¡ Medium âš ï¸ *Use dev branch*
- [ ] **T3**: End-to-end integration tests - ğŸŸ¢ Low
- [ ] **T4**: Stress tests - ğŸŸ¢ Low

### 3.4 Documentation

- [ ] **D1**: OpenAPI/Swagger spec - ğŸŸ¡ Medium âš ï¸ *Use dev branch*
- [ ] **D2**: Architecture documentation - ğŸŸ¢ Low
- [ ] **D3**: Contribution guide - ğŸŸ¢ Low

### 3.5 Architecture Improvements (from Cordon analysis)

*Sorted by complexity (simple â†’ complex):*

- [ ] **A1**: Add `py.typed` marker + mypy config in pyproject.toml - ğŸŸ¢ Low
- [ ] **A2**: Integrate ruff linter (replace flake8/isort) - ğŸŸ¢ Low  
- [ ] **A3**: Add pytest-cov with `--cov-report=term-missing` - ğŸŸ¢ Low
- [ ] **A4**: Convert `NodeContext` to `@dataclass(frozen=True)` + validation - ğŸŸ¡ Medium âš ï¸ *Use dev branch*
- [ ] **A5**: Create `LLMProvider` Protocol for unified LLM interface - ğŸŸ¡ Medium âš ï¸ *Use dev branch*
- [ ] **A6**: Refactor analyzer.py to Pipeline pattern (captureâ†’parseâ†’classifyâ†’suggest) - ğŸ”´ High âš ï¸ *Use dev branch*

> [!IMPORTANT]
> Items marked with âš ï¸ should be developed on a separate `dev` branch to prevent breaking existing functionality. Merge to `main` only after thorough testing.

---

## 4. Priority Phases

### Phase 1: Immediate Improvements (1-2 weeks) âœ… COMPLETED

1. **R1** Error handling refactor
2. **R2** Thread safety
3. **R4** XSS protection
4. **T1** API tests

### Phase 2: Feature Enhancement (2-4 weeks) âœ… COMPLETED

1. **F3** Workflow context âœ…
2. **F1** History persistence âœ…
3. **R3** Session reuse âœ…
4. **F6** Provider quick switch â³ *Deferred to next cycle*

### Phase 3: Advanced Features (1-2 months)

1. **A1-A3** Quick architecture wins (py.typed, ruff, pytest-cov)
2. **F4** Statistics dashboard
3. **T2** Frontend tests
4. **A4-A5** Dataclass + Protocol refactoring

### Phase 4: Major Refactoring (2+ months)

1. **A6** Pipeline architecture refactor
2. **F2** Pattern hot-reload
3. **D1-D3** Full documentation

---

## 5. v2.0 Major Feature: LLM Debug Chat Interface ğŸ†•

> **Target Version**: v2.0.0  
> **Status**: ğŸ“‹ Planning  
> **Priority**: ğŸ”´ High  
> **Branch**: `feature/chat-ui`

### 5.1 Feature Overview

Transform the current single-shot AI analysis into a full conversational debugging experience, allowing users to have multi-turn dialogues with LLM about their errors.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ¥ ComfyUI Doctor                               [â”€] [Ã—]   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€ Error Card â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ âš ï¸ RuntimeError: CUDA out of memory                   â”‚ â”‚
â”‚  â”‚ ğŸ• 14:32:05 | Node #42: KSampler                      â”‚ â”‚
â”‚  â”‚ [ğŸ” Locate] [âœ¨ Chat with AI] [ğŸ“‹ Copy Error]         â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€ AI Chat (Expanded) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ ğŸ¤– Based on the error, here are solutions:            â”‚ â”‚
â”‚  â”‚    1. **Reduce batch size** to 1                      â”‚ â”‚
â”‚  â”‚    2. Use `--lowvram` flag                            â”‚ â”‚
â”‚  â”‚    ```bash                                            â”‚ â”‚
â”‚  â”‚    python main.py --lowvram                           â”‚ â”‚
â”‚  â”‚    ```                                                â”‚ â”‚
â”‚  â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚ â”‚
â”‚  â”‚ ğŸ‘¤ What if I'm already using --lowvram?               â”‚ â”‚
â”‚  â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚ â”‚
â”‚  â”‚ ğŸ¤– If --lowvram isn't enough, try:                    â”‚ â”‚
â”‚  â”‚    - Split workflow into smaller segments...        â–¼ â”‚ â”‚
â”‚  â”‚                                                        â”‚ â”‚
â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” [Send] [ğŸ”„]      â”‚ â”‚
â”‚  â”‚ â”‚ Ask a follow-up question...      â”‚                  â”‚ â”‚
â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 5.2 Design Inspiration

| Source | Key Takeaways |
|--------|---------------|
| **ChatGPT/Claude Web** | Message list layout, streaming output, Markdown rendering |
| **VS Code Copilot Chat** | Sidebar integration, code block actions, context awareness |
| **Intercom/Drift Widgets** | Expandable panel, minimize/maximize, session persistence |

### 5.3 Feature Breakdown

#### Core Features (v2.0.0)

| ID | Feature | Description | Complexity |
|----|---------|-------------|------------|
| **C1** | Message List | User/AI message alternating display with scroll | ğŸŸ¢ Low |
| **C2** | Streaming Output | SSE real-time display with typewriter effect | ğŸŸ¡ Medium |
| **C3** | Markdown Rendering | Headers, lists, code blocks, inline code | ğŸŸ¢ Low |
| **C4** | Code Highlighting | Syntax highlighting + one-click copy | ğŸŸ¢ Low |
| **C5** | Context Injection | Auto-attach error info + Node Context to first message | ğŸŸ¢ Low |
| **C6** | Session History | Retain conversation in frontend session, clearable | ğŸŸ¢ Low |
| **C7** | Regenerate | Re-request last AI response | ğŸŸ¢ Low |
| **C8** | Quick Follow-ups | Preset question buttons (e.g., "Explain more", "Show code") | ğŸŸ¢ Low |

#### Backend Features

| ID | Feature | Description | Complexity |
|----|---------|-------------|------------|
| **C9** | Chat API Endpoint | `POST /doctor/chat` supporting multi-turn dialogue | ğŸŸ¡ Medium |
| **C10** | SSE StreamResponse | `aiohttp` Server-Sent Events for streaming | ğŸŸ¡ Medium |
| **C11** | Context Management | Build system prompt with error + workflow context | ğŸŸ¢ Low |

#### Future Enhancements (v2.1+)

| ID | Feature | Description | Complexity |
|----|---------|-------------|------------|
| **C12** | Chat History Persistence | Save/load conversation history | ğŸŸ¡ Medium |
| **C13** | Export Conversation | Export chat as Markdown/JSON | ğŸŸ¢ Low |
| **C14** | Multi-Error Context | Reference multiple errors in one chat | ğŸŸ¡ Medium |
| **C15** | Code Actions | "Apply fix" button for specific suggestions | ğŸ”´ High |

### 5.4 Technical Architecture

```mermaid
sequenceDiagram
    participant U as User
    participant UI as ChatPanel (JS)
    participant API as /doctor/chat
    participant LLM as LLM Provider

    U->>UI: Click "Chat with AI"
    UI->>UI: Initialize with error context
    UI->>API: POST {messages, error_context, stream:true}
    API->>LLM: Forward with system prompt
    loop SSE Stream
        LLM-->>API: Token chunk
        API-->>UI: data: {"delta": "...", "done": false}
        UI->>UI: Append to message, render Markdown
    end
    LLM-->>API: Complete
    API-->>UI: data: {"delta": "", "done": true}
    U->>UI: Type follow-up question
    UI->>API: POST {messages: [...history, new], stream:true}
```

### 5.5 Technology Stack

| Component | Choice | Rationale |
|-----------|--------|-----------|
| **Markdown Renderer** | marked.js (CDN) | Lightweight (~40KB gzip), zero dependencies |
| **Code Highlighting** | highlight.js (CDN) | Wide language support, on-demand loading |
| **Streaming Parser** | Native EventSource | Browser built-in, no extra dependencies |
| **State Management** | Plain JS Map/Array | Maintain zero-dependency principle |

### 5.6 API Design

#### New Endpoint: `POST /doctor/chat`

**Request:**

```json
{
  "messages": [
    {"role": "user", "content": "Why am I getting this OOM error?"},
    {"role": "assistant", "content": "Based on the error..."},
    {"role": "user", "content": "What if I'm already using --lowvram?"}
  ],
  "error_context": {
    "error": "RuntimeError: CUDA out of memory...",
    "node_context": {"node_id": "42", "node_name": "KSampler", ...}
  },
  "api_key": "sk-...",
  "base_url": "https://api.openai.com/v1",
  "model": "gpt-4o",
  "stream": true
}
```

**Response (SSE):**

```
data: {"delta": "If ", "done": false}
data: {"delta": "--lowvram ", "done": false}
data: {"delta": "isn't enough, try:", "done": false}
data: {"delta": "", "done": true, "usage": {"prompt_tokens": 150, "completion_tokens": 89}}
```

### 5.7 File Structure Changes

```
web/
â”œâ”€â”€ doctor.js           # Add Chat settings registration
â”œâ”€â”€ doctor_ui.js        # Add ChatPanel integration
â”œâ”€â”€ doctor_api.js       # Add streamChat() method
â”œâ”€â”€ doctor_chat.js      # ã€NEWã€‘Chat UI module
â””â”€â”€ doctor_chat.css     # ã€NEWã€‘Chat styles (or embedded)

__init__.py             # Add /doctor/chat streaming endpoint
```

### 5.8 Implementation Phases

#### Phase 2.0-A: Basic Chat (1-2 weeks)

| Task | Est. Hours | Dependencies |
|------|------------|--------------|
| Design chat UI styles (CSS) | 2h | - |
| Implement ChatPanel class | 4h | - |
| Implement message list rendering | 3h | ChatPanel |
| Integrate marked.js + highlight.js | 2h | - |
| Backend `/doctor/chat` endpoint (non-streaming) | 3h | - |
| Frontend-backend integration test | 2h | All above |

#### Phase 2.0-B: Streaming & Advanced (1-2 weeks)

| Task | Est. Hours | Dependencies |
|------|------------|--------------|
| Backend SSE StreamResponse | 4h | - |
| Frontend EventSource parsing | 3h | - |
| Typewriter animation effect | 2h | EventSource |
| Regenerate functionality | 2h | - |
| Quick follow-up buttons | 2h | - |
| Code copy button | 1h | highlight.js |

#### Phase 2.0-C: Polish & Testing (1 week)

| Task | Est. Hours | Dependencies |
|------|------------|--------------|
| Error handling & retry mechanism | 2h | - |
| Session history management | 2h | - |
| Responsive design (mobile-friendly) | 2h | - |
| Unit tests | 3h | - |
| Documentation update | 2h | - |

### 5.9 Success Metrics

| Metric | Target |
|--------|--------|
| First message response time | < 3s (streaming start) |
| Chat panel load time | < 500ms |
| Markdown render time | < 100ms per message |
| User satisfaction (if trackable) | > 80% positive feedback |

### 5.10 Risks & Mitigations

| Risk | Impact | Mitigation |
|------|--------|------------|
| SSE not supported by proxy | Medium | Fallback to polling mode |
| Large context overflow | High | Token counting + truncation |
| CDN dependency failure | Low | Bundle fallback or local copy |
| LLM rate limiting | Medium | Exponential backoff + user notification |

---
---

# ComfyUI-Doctor å°ˆæ¡ˆæ¶æ§‹èˆ‡æ“´å±•è¦åŠƒ

## ä¸€ã€å°ˆæ¡ˆæ¶æ§‹

### 1.1 æ ¸å¿ƒæ¨¡çµ„çµæ§‹

```mermaid
graph TD
    A[prestartup_script.py] -->|æ—©æœŸ Hook| B[__init__.py]
    B --> C[logger.py]
    B --> D[analyzer.py]
    B --> E[i18n.py]
    B --> F[config.py]
    B --> G[nodes.py]
    
    C --> H[AsyncFileWriter]
    C --> I[SmartLogger]
    
    D --> J[ErrorAnalyzer]
    D --> K[NodeContext]
    
    B --> L[API Endpoints]
    L --> M[/debugger/last_analysis]
    L --> N[/debugger/history]
    L --> O[/debugger/set_language]
    L --> P[/doctor/analyze]
    L --> Q[/doctor/verify_key]
    L --> R[/doctor/list_models]
    
    S[web/doctor.js] --> T[Settings Registration]
    U[web/doctor_ui.js] --> V[Sidebar Panel]
    U --> W[Error Cards]
    U --> X[AI Analysis]
    Y[web/doctor_api.js] --> Z[Fetch Wrapper]
```

### 1.2 æ¨¡çµ„åŠŸèƒ½æ¦‚è¦½

| æ¨¡çµ„ | è¡Œæ•¸ | åŠŸèƒ½ |
|------|------|------|
| `prestartup_script.py` | 102 | æœ€æ—©çš„æ—¥èªŒæ””æˆª Hookï¼ˆåœ¨ custom_nodes è¼‰å…¥å‰ï¼‰ |
| `__init__.py` | 477 | ä¸»å…¥å£ï¼šå®Œæ•´ Logger å®‰è£ã€6 å€‹ API ç«¯é»ã€LLM æ•´åˆ |
| `logger.py` | 339 | æ™ºèƒ½æ—¥èªŒå™¨ï¼šéåŒæ­¥å¯«å…¥ã€éŒ¯èª¤å³æ™‚åˆ†æã€æ­·å²è¨˜éŒ„ |
| `analyzer.py` | 271 | éŒ¯èª¤åˆ†æå™¨ï¼š20+ éŒ¯èª¤æ¨¡å¼ã€ç¯€é»ä¸Šä¸‹æ–‡æ“·å– |
| `i18n.py` | 190 | åœ‹éš›åŒ–ï¼š4 èªè¨€ï¼ˆen, zh_TW, zh_CN, jaï¼‰ |
| `config.py` | 65 | é…ç½®ç®¡ç†ï¼šdataclass + JSON æŒä¹…åŒ– |
| `nodes.py` | 179 | Smart Debug Nodeï¼šæ·±åº¦æ•¸æ“šæª¢æŸ¥ |
| `doctor.js` | 528 | ComfyUI è¨­å®šé¢æ¿æ•´åˆ |
| `doctor_ui.js` | 778 | Sidebar UIã€éŒ¯èª¤å¡ç‰‡ã€AI åˆ†æè§¸ç™¼ |
| `doctor_api.js` | 114 | API å°è£å±¤ |

---

## äºŒã€æ¶æ§‹å¼·å¥æ€§è©•ä¼°

### 2.1 å„ªé» âœ…

1. **é›™éšæ®µæ—¥èªŒç³»çµ±**
   - `prestartup_script.py` ç¢ºä¿åœ¨æ‰€æœ‰ custom_nodes è¼‰å…¥å‰å°±é–‹å§‹æ•ç²
   - `SmartLogger` ç„¡ç¸«å‡ç´šï¼Œä¸éºå¤±æ—©æœŸæ—¥èªŒ

2. **éåŒæ­¥ I/O**
   - `AsyncFileWriter` ä½¿ç”¨èƒŒæ™¯åŸ·è¡Œç·’ + æ‰¹æ¬¡å¯«å…¥
   - ä¸æœƒé˜»å¡ä¸»åŸ·è¡Œç·’ï¼ˆé—œéµæ–¼é«˜é » stdout/stderrï¼‰

3. **åŸ·è¡Œç·’å®‰å…¨**
   - `threading.Lock` ä¿è­· traceback buffer
   - `weakref.finalize` ç¢ºä¿è³‡æºæ¸…ç†

4. **å®Œæ•´çš„éŒ¯èª¤åˆ†æç®¡ç·š**
   - 20+ é å®šç¾©éŒ¯èª¤æ¨¡å¼ï¼ˆ`PATTERNS` listï¼‰
   - æ­£å‰‡è¡¨é”å¼ LRU å¿«å–ï¼ˆ`@functools.lru_cache`ï¼‰
   - ç¯€é»ä¸Šä¸‹æ–‡æ“·å–ï¼ˆNode ID, Name, Class, Custom Pathï¼‰

5. **LLM æ•´åˆæ¶æ§‹**
   - æ”¯æ´ OpenAI/DeepSeek/Ollama/LMStudio
   - æœ¬åœ° LLM è‡ªå‹•åµæ¸¬ï¼ˆä¸éœ€è¦ API Keyï¼‰
   - 60 ç§’ timeout é˜²æ­¢è«‹æ±‚æ›èµ·

6. **å‰ç«¯æ•´åˆ**
   - åŸç”Ÿ ComfyUI Settings API æ•´åˆ
   - WebSocket `execution_error` äº‹ä»¶è¨‚é–±ï¼ˆå³æ™‚é€šçŸ¥ï¼‰
   - è¼ªè©¢ + äº‹ä»¶é›™é€šé“

7. **åœ‹éš›åŒ–**
   - 4 èªè¨€æ”¯æ´ï¼Œçµæ§‹åŒ–ç¿»è­¯å­—å…¸
   - å¯æ“´å±•çš„ `SUGGESTIONS` çµæ§‹

### 2.2 æ½›åœ¨å•é¡Œèˆ‡æ”¹é€²é» âš ï¸

#### P1: éŒ¯èª¤è™•ç†

| å•é¡Œ | ä½ç½® | å»ºè­° |
|------|------|------|
| `except Exception: pass` éæ–¼å¯¬æ³› | `logger.py:184`, `__init__.py:56` | è‡³å°‘è¨˜éŒ„åˆ° log æˆ–ä½¿ç”¨ç‰¹å®š Exception |
| `api_verify_key` ä¸­ `data` å¯èƒ½æœªå®šç¾© | `__init__.py:364` | ä½¿ç”¨ `.get()` å‰å…ˆç¢ºèªæˆ–ç”¨ try block å¤–çš„é è¨­å€¼ |

#### P2: ç«¶æ…‹æ¢ä»¶ï¼ˆRace Conditionsï¼‰

| å•é¡Œ | ä½ç½® | å»ºè­° |
|------|------|------|
| `_analysis_history` æ˜¯ `deque`ï¼Œå¤šåŸ·è¡Œç·’å¯«å…¥å¯èƒ½ä¸å®‰å…¨ | `logger.py:269` | ä½¿ç”¨ `threading.Lock` ä¿è­·æˆ–æ”¹ç”¨ `collections.deque` with `maxlen` + å–®ä¸€å¯«å…¥è€…æ¨¡å¼ |
| `SmartLogger._instances` ç„¡é–ä¿è­· | `logger.py:146` | åŠ å…¥é–ä¿è­·æˆ–ç¢ºä¿å–®ä¸€åŸ·è¡Œç·’æ“ä½œ |

#### P3: è³‡æºæ´©æ¼é¢¨éšª

| å•é¡Œ | ä½ç½® | å»ºè­° |
|------|------|------|
| `prestartup_script.py` çš„ `_log_file` åƒ…åœ¨ finalizer è™•ç† | `prestartup_script.py:45` | åŠ å…¥é¡¯å¼ `close()` æ–¹æ³• |
| `aiohttp.ClientSession` åœ¨æ¯æ¬¡è«‹æ±‚å»ºç«‹ | `__init__.py:258,341,403` | è€ƒæ…®è¤‡ç”¨ session æˆ–ç¢ºä¿ä¾‹å¤–æ™‚æ­£ç¢ºé—œé–‰ |

#### P4: å‰ç«¯ç©©å¥æ€§

| å•é¡Œ | ä½ç½® | å»ºè­° |
|------|------|------|
| `locateNodeOnCanvas` ä¾è³´ `app.graph._nodes_by_id` å…§éƒ¨ API | `doctor_ui.js:243` | åŠ å…¥ fallback æˆ–æª¢æŸ¥ API å­˜åœ¨ |
| ç„¡ XSS é˜²è­·æ–¼ AI analysis çµæœ | `doctor_ui.js:398` | ç¢ºä¿ `innerHTML` è¼¸å…¥å·²æ·¨åŒ– |

#### P5: æ¸¬è©¦è¦†è“‹

| å•é¡Œ | èªªæ˜ |
|------|------|
| ç„¡ API ç«¯é»æ¸¬è©¦ | ç¼ºå°‘ `/doctor/analyze`, `/doctor/verify_key` ç­‰ API çš„ mock æ¸¬è©¦ |
| ç„¡å‰ç«¯æ¸¬è©¦ | JavaScript ç„¡å–®å…ƒæ¸¬è©¦ |
| æ•´åˆæ¸¬è©¦ä¾è³´ mock | `test_integrations.py` mock äº† torch/serverï¼Œç„¡æ³•æ¸¬çœŸå¯¦æ•´åˆ |

---

## ä¸‰ã€å»¶ä¼¸æ“´å±•é …ç›® Todo-List

### 3.1 åŠŸèƒ½æ“´å±•ï¼ˆFeatureï¼‰

- [ ] **F1: éŒ¯èª¤æ­·å²æŒä¹…åŒ–**
  - å°‡ `_analysis_history` å¯«å…¥ SQLite æˆ– JSON æª”
  - æ”¯æ´è·¨é‡å•ŸæŸ¥çœ‹æ­·å²
  - å„ªå…ˆç´šï¼šğŸŸ¡ Medium âš ï¸ *ä½¿ç”¨ dev branch é–‹ç™¼*

- [ ] **F2: éŒ¯èª¤æ¨¡å¼ç†±æ›´æ–°**
  - å¾å¤–éƒ¨ JSON/YAML è¼‰å…¥ `PATTERNS`
  - å…è¨±ä½¿ç”¨è€…è‡ªè¨‚éŒ¯èª¤æ¨¡å¼
  - å„ªå…ˆç´šï¼šğŸŸ¢ Low

- [ ] **F3: Workflow ä¸Šä¸‹æ–‡æ“·å–**
  - åœ¨éŒ¯èª¤ç™¼ç”Ÿæ™‚æ•ç²ç•¶å‰ workflow JSON
  - æä¾›çµ¦ LLM æ›´å®Œæ•´çš„ä¸Šä¸‹æ–‡
  - å„ªå…ˆç´šï¼šğŸ”´ High âš ï¸ *ä½¿ç”¨ dev branch é–‹ç™¼*

- [ ] **F4: éŒ¯èª¤çµ±è¨ˆå„€è¡¨æ¿**
  - æŒ‰ç¯€é»/éŒ¯èª¤é¡å‹åˆ†çµ„çµ±è¨ˆ
  - è¦–è¦ºåŒ–å¸¸è¦‹éŒ¯èª¤ç†±é»
  - å„ªå…ˆç´šï¼šğŸŸ¡ Medium âš ï¸ *ä½¿ç”¨ dev branch é–‹ç™¼*

- [ ] **F5: ç¯€é»å¥åº·è©•åˆ†**
  - è¿½è¹¤å„ custom_node çš„éŒ¯èª¤é »ç‡
  - æ¨™è¨˜é«˜é¢¨éšªç¯€é»
  - å„ªå…ˆç´šï¼šğŸŸ¢ Low

- [ ] **F6: å¤š LLM Provider å¿«é€Ÿåˆ‡æ›**
  - åœ¨ UI ä¸­æä¾›ä¸‹æ‹‰é¸å–®å¿«é€Ÿåˆ‡æ› preset
  - é è¨­é…ç½®ï¼šOpenAI/DeepSeek/Ollama
  - å„ªå…ˆç´šï¼šğŸŸ¡ Medium âš ï¸ *ä½¿ç”¨ dev branch é–‹ç™¼*

- [ ] **F7: éŒ¯èª¤è‡ªå‹•ä¿®å¾©å»ºè­°åŸ·è¡Œ**
  - å°æ–¼ç‰¹å®šéŒ¯èª¤ï¼ˆå¦‚ pip install ç¼ºå¤±æ¨¡çµ„ï¼‰ï¼Œæä¾›ä¸€éµåŸ·è¡Œ
  - éœ€è©•ä¼°å®‰å…¨æ€§é¢¨éšª
  - å„ªå…ˆç´šï¼šğŸŸ¢ Low

### 3.2 ç©©å¥æ€§æ”¹é€²ï¼ˆRobustnessï¼‰

- [ ] **R1: å…¨é¢çš„éŒ¯èª¤è™•ç†é‡æ§‹**
  - æ›¿æ›æ‰€æœ‰ `except: pass` ç‚ºç‰¹å®šéŒ¯èª¤è™•ç†
  - åŠ å…¥æ—¥èªŒè¨˜éŒ„
  - å„ªå…ˆç´šï¼šğŸ”´ High

- [ ] **R2: åŸ·è¡Œç·’å®‰å…¨åŠ å›º**
  - ç‚º `_analysis_history` åŠ å…¥é–
  - å¯©è¨ˆæ‰€æœ‰å…±äº«ç‹€æ…‹
  - å„ªå…ˆç´šï¼šğŸ”´ High

- [ ] **R3: Session è¤‡ç”¨**
  - ç‚º LLM API å‘¼å«å»ºç«‹å¯è¤‡ç”¨çš„ `aiohttp.ClientSession`
  - åŠ å…¥é€£ç·šæ± ç®¡ç†
  - å„ªå…ˆç´šï¼šğŸŸ¡ Medium âš ï¸ *ä½¿ç”¨ dev branch é–‹ç™¼*

- [ ] **R4: XSS é˜²è­·**
  - ç¢ºä¿æ‰€æœ‰ `innerHTML` ä½¿ç”¨éƒ½ç¶“éæ·¨åŒ–
  - å° LLM å›æ‡‰ä½¿ç”¨ markdown æ¸²æŸ“å™¨
  - å„ªå…ˆç´šï¼šğŸ”´ High

- [ ] **R5: å‰ç«¯éŒ¯èª¤é‚Šç•Œ**
  - åŠ å…¥ try-catch æ–¼é—œéµå‰ç«¯å‡½æ•¸
  - é¡¯ç¤ºå‹å–„éŒ¯èª¤è¨Šæ¯è€Œééœé»˜å¤±æ•—
  - å„ªå…ˆç´šï¼šğŸŸ¡ Medium âš ï¸ *ä½¿ç”¨ dev branch é–‹ç™¼*

### 3.3 æ¸¬è©¦æ“´å……ï¼ˆTestingï¼‰

- [ ] **T1: API ç«¯é»å–®å…ƒæ¸¬è©¦**
  - ä½¿ç”¨ `aiohttp.test_utils` æ¸¬è©¦æ‰€æœ‰ç«¯é»
  - åŒ…å«æ­£å¸¸/éŒ¯èª¤å›æ‡‰
  - å„ªå…ˆç´šï¼šğŸ”´ High

- [ ] **T2: å‰ç«¯äº’å‹•æ¸¬è©¦**
  - ä½¿ç”¨ Playwright æˆ– Puppeteer
  - æ¸¬è©¦ Settings é¢æ¿ã€Sidebarã€AI åˆ†æ
  - å„ªå…ˆç´šï¼šğŸŸ¡ Medium âš ï¸ *ä½¿ç”¨ dev branch é–‹ç™¼*

- [ ] **T3: ç«¯å°ç«¯æ•´åˆæ¸¬è©¦**
  - åœ¨çœŸå¯¦ ComfyUI ç’°å¢ƒä¸­åŸ·è¡Œ
  - æ¨¡æ“¬éŒ¯èª¤ä¸¦é©—è­‰æ•ç²
  - å„ªå…ˆç´šï¼šğŸŸ¢ Low

- [ ] **T4: å£“åŠ›æ¸¬è©¦**
  - é«˜é » stdout è¼¸å‡ºä¸é˜»å¡
  - å¤§é‡éŒ¯èª¤æ­·å²è¨˜éŒ„æ•ˆèƒ½
  - å„ªå…ˆç´šï¼šğŸŸ¢ Low

### 3.4 æ–‡ä»¶èˆ‡ DXï¼ˆDocumentationï¼‰

- [ ] **D1: API æ–‡ä»¶**
  - ç‚ºæ‰€æœ‰ API ç«¯é»æ’°å¯« OpenAPI/Swagger è¦æ ¼
  - å„ªå…ˆç´šï¼šğŸŸ¡ Medium âš ï¸ *ä½¿ç”¨ dev branch é–‹ç™¼*

- [ ] **D2: æ¶æ§‹æ–‡ä»¶**
  - ç¹ªè£½å®Œæ•´è³‡æ–™æµåœ–
  - èªªæ˜å„æ¨¡çµ„è²¬ä»»
  - å„ªå…ˆç´šï¼šğŸŸ¢ Low

- [ ] **D3: è²¢ç»æŒ‡å—**
  - å¦‚ä½•æ–°å¢éŒ¯èª¤æ¨¡å¼
  - å¦‚ä½•æ–°å¢èªè¨€
  - å¦‚ä½•æ–°å¢ LLM Provider
  - å„ªå…ˆç´šï¼šğŸŸ¢ Low

### 3.5 æ¶æ§‹æ”¹é€²ï¼ˆåƒè€ƒ Cordon å°ˆæ¡ˆï¼‰

*æŒ‰è¤‡é›œåº¦æ’åºï¼ˆç°¡å–® â†’ è¤‡é›œï¼‰ï¼š*

- [ ] **A1: åŠ å…¥ py.typed + mypy é…ç½®**
  - åœ¨ pyproject.toml åŠ å…¥åš´æ ¼å‹åˆ¥æª¢æŸ¥
  - å„ªå…ˆç´šï¼šğŸŸ¢ Low

- [ ] **A2: æ•´åˆ ruff linter**
  - å–ä»£ flake8/isortï¼Œçµ±ä¸€ç¨‹å¼ç¢¼é¢¨æ ¼
  - å„ªå…ˆç´šï¼šğŸŸ¢ Low

- [ ] **A3: åŠ å…¥ pytest-cov è¦†è“‹ç‡å ±å‘Š**
  - ä½¿ç”¨ `--cov-report=term-missing` é¡¯ç¤ºæœªè¦†è“‹è¡Œ
  - å„ªå…ˆç´šï¼šğŸŸ¢ Low

- [ ] **A4: NodeContext æ”¹ç‚º frozen dataclass**
  - ä½¿ç”¨ `@dataclass(frozen=True)` + `__post_init__` é©—è­‰
  - å„ªå…ˆç´šï¼šğŸŸ¡ Medium âš ï¸ *ä½¿ç”¨ dev branch é–‹ç™¼*

- [ ] **A5: å»ºç«‹ LLMProvider Protocol**
  - çµ±ä¸€ OpenAI/Ollama/DeepSeek ä»‹é¢
  - å„ªå…ˆç´šï¼šğŸŸ¡ Medium âš ï¸ *ä½¿ç”¨ dev branch é–‹ç™¼*

- [ ] **A6: é‡æ§‹ analyzer.py ç‚º Pipeline æ¶æ§‹**
  - æ¡ç”¨ captureâ†’parseâ†’classifyâ†’suggest ç®¡ç·šæ¨¡å¼
  - å„ªå…ˆç´šï¼šğŸ”´ High âš ï¸ *ä½¿ç”¨ dev branch é–‹ç™¼*

> [!IMPORTANT]
> æ¨™è¨» âš ï¸ çš„é …ç›®æ‡‰åœ¨ç¨ç«‹çš„ `dev` åˆ†æ”¯ä¸Šé–‹ç™¼ï¼Œä»¥é¿å…ç ´å£ç¾æœ‰åŠŸèƒ½ã€‚å®Œæˆå……åˆ†æ¸¬è©¦å¾Œå†åˆä½µè‡³ `main`ã€‚

---

## å››ã€å„ªå…ˆç´šæ’åºå»ºè­°

### Phase 1: ç«‹å³æ”¹é€²ï¼ˆ1-2 é€±ï¼‰âœ… å·²å®Œæˆ

1. **R1** éŒ¯èª¤è™•ç†é‡æ§‹
2. **R2** åŸ·è¡Œç·’å®‰å…¨
3. **R4** XSS é˜²è­·
4. **T1** API æ¸¬è©¦

### Phase 2: åŠŸèƒ½å¢å¼·ï¼ˆ2-4 é€±ï¼‰

1. **F3** Workflow ä¸Šä¸‹æ–‡
2. **F1** æ­·å²æŒä¹…åŒ–
3. **R3** Session è¤‡ç”¨
4. **F6** Provider å¿«é€Ÿåˆ‡æ›

### Phase 3: é€²éšåŠŸèƒ½ï¼ˆ1-2 æœˆï¼‰

1. **A1-A3** å¿«é€Ÿæ¶æ§‹å„ªåŒ–ï¼ˆpy.typedã€ruffã€pytest-covï¼‰
2. **F4** çµ±è¨ˆå„€è¡¨æ¿
3. **T2** å‰ç«¯æ¸¬è©¦
4. **A4-A5** Dataclass + Protocol é‡æ§‹

### Phase 4: é‡å¤§é‡æ§‹ï¼ˆ2+ æœˆï¼‰

1. **A6** Pipeline æ¶æ§‹é‡æ§‹
2. **F2** æ¨¡å¼ç†±æ›´æ–°
3. **D1-D3** å®Œæ•´æ–‡ä»¶

---

## äº”ã€v2.0 é‡å¤§åŠŸèƒ½ï¼šLLM é™¤éŒ¯å°è©±ä»‹é¢ ğŸ†•

> **ç›®æ¨™ç‰ˆæœ¬**ï¼šv2.0.0  
> **ç‹€æ…‹**ï¼šğŸ“‹ è¦åŠƒä¸­  
> **å„ªå…ˆç´š**ï¼šğŸ”´ High  
> **åˆ†æ”¯**ï¼š`feature/chat-ui`

### 5.1 åŠŸèƒ½æ¦‚è¿°

å°‡ç›®å‰çš„å–®æ¬¡ AI åˆ†æå‡ç´šç‚ºå®Œæ•´çš„å°è©±å¼é™¤éŒ¯é«”é©—ï¼Œè®“ä½¿ç”¨è€…èƒ½èˆ‡ LLM é€²è¡Œå¤šè¼ªå°è©±ä¾†è§£æ±ºéŒ¯èª¤å•é¡Œã€‚

**è¨­è¨ˆäº®é»**ï¼š

- ğŸ“ å¤šè¼ªå°è©±ï¼šä¿æŒä¸Šä¸‹æ–‡çš„é€£çºŒè¿½å•
- âš¡ ä¸²æµè¼¸å‡ºï¼šå³æ™‚é¡¯ç¤º AI å›æ‡‰ï¼Œæå‡é«”é©—
- ğŸ¨ Markdown æ¸²æŸ“ï¼šæ”¯æ´ç¨‹å¼ç¢¼å€å¡Šã€åˆ—è¡¨ã€æ¨™é¡Œ
- ğŸ“‹ ä¸€éµè¤‡è£½ï¼šç¨‹å¼ç¢¼å€å¡Šæ”¯æ´å¿«é€Ÿè¤‡è£½
- ğŸ”— ä¸Šä¸‹æ–‡é—œè¯ï¼šè‡ªå‹•å°‡éŒ¯èª¤è³‡è¨Šå‚³éçµ¦ LLM

### 5.2 UI è¨­è¨ˆè‰åœ–

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ¥ ComfyUI Doctor                               [â”€] [Ã—]   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€ éŒ¯èª¤å¡ç‰‡ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ âš ï¸ RuntimeError: CUDA out of memory                   â”‚ â”‚
â”‚  â”‚ ğŸ• 14:32:05 | ç¯€é» #42: KSampler                      â”‚ â”‚
â”‚  â”‚ [ğŸ” å®šä½ç¯€é»] [âœ¨ èˆ‡ AI å°è©±] [ğŸ“‹ è¤‡è£½éŒ¯èª¤]           â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€ AI å°è©±ï¼ˆå±•é–‹ï¼‰â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ ğŸ¤– æ ¹æ“šéŒ¯èª¤åˆ†æï¼Œå»ºè­°ä»¥ä¸‹è§£æ±ºæ–¹æ¡ˆï¼š                   â”‚ â”‚
â”‚  â”‚    1. **é™ä½ batch size** è‡³ 1                        â”‚ â”‚
â”‚  â”‚    2. ä½¿ç”¨ `--lowvram` å•Ÿå‹•åƒæ•¸                       â”‚ â”‚
â”‚  â”‚    ```bash                                            â”‚ â”‚
â”‚  â”‚    python main.py --lowvram                           â”‚ â”‚
â”‚  â”‚    ```                                                â”‚ â”‚
â”‚  â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚ â”‚
â”‚  â”‚ ğŸ‘¤ å¦‚æœæˆ‘å·²ç¶“åœ¨ç”¨ --lowvram äº†å‘¢ï¼Ÿ                    â”‚ â”‚
â”‚  â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚ â”‚
â”‚  â”‚ ğŸ¤– å¦‚æœ --lowvram ä»ç„¶ä¸å¤ ï¼Œå¯ä»¥å˜—è©¦ï¼š                â”‚ â”‚
â”‚  â”‚    - å°‡å·¥ä½œæµæ‹†åˆ†æˆè¼ƒå°çš„ç‰‡æ®µ...                    â–¼ â”‚ â”‚
â”‚  â”‚                                                        â”‚ â”‚
â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” [ç™¼é€] [ğŸ”„]      â”‚ â”‚
â”‚  â”‚ â”‚ è¼¸å…¥è¿½å•å•é¡Œ...                  â”‚                  â”‚ â”‚
â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 5.3 åŠŸèƒ½ç´°é …

#### æ ¸å¿ƒåŠŸèƒ½ï¼ˆv2.0.0ï¼‰

| ç·¨è™Ÿ | åŠŸèƒ½ | æè¿° | è¤‡é›œåº¦ |
|------|------|------|--------|
| **C1** | è¨Šæ¯åˆ—è¡¨ | ç”¨æˆ¶/AI è¨Šæ¯äº¤æ›¿é¡¯ç¤ºï¼Œæ”¯æ´æ»¾å‹• | ğŸŸ¢ Low |
| **C2** | ä¸²æµè¼¸å‡º | SSE å³æ™‚é¡¯ç¤º + æ‰“å­—æ©Ÿæ•ˆæœ | ğŸŸ¡ Medium |
| **C3** | Markdown æ¸²æŸ“ | æ¨™é¡Œã€åˆ—è¡¨ã€ç¨‹å¼ç¢¼å€å¡Šã€è¡Œå…§ç¨‹å¼ç¢¼ | ğŸŸ¢ Low |
| **C4** | ç¨‹å¼ç¢¼é«˜äº® | èªæ³•é«˜äº® + ä¸€éµè¤‡è£½æŒ‰éˆ• | ğŸŸ¢ Low |
| **C5** | ä¸Šä¸‹æ–‡æ³¨å…¥ | é¦–å‰‡è¨Šæ¯è‡ªå‹•é™„å¸¶éŒ¯èª¤è³‡è¨Š + Node Context | ğŸŸ¢ Low |
| **C6** | å°è©±æ­·å² | å‰ç«¯ Session å…§ä¿ç•™ï¼Œå¯æ‰‹å‹•æ¸…é™¤ | ğŸŸ¢ Low |
| **C7** | é‡æ–°ç”Ÿæˆ | é‡æ–°è«‹æ±‚æœ€å¾Œä¸€å‰‡ AI å›æ‡‰ | ğŸŸ¢ Low |
| **C8** | å¿«é€Ÿè¿½å• | é è¨­å•é¡ŒæŒ‰éˆ•ï¼ˆã€Œè©³ç´°è§£é‡‹ã€ã€Œé¡¯ç¤ºç¨‹å¼ç¢¼ã€ï¼‰ | ğŸŸ¢ Low |

#### å¾Œç«¯åŠŸèƒ½

| ç·¨è™Ÿ | åŠŸèƒ½ | æè¿° | è¤‡é›œåº¦ |
|------|------|------|--------|
| **C9** | Chat API ç«¯é» | `POST /doctor/chat` æ”¯æ´å¤šè¼ªå°è©± | ğŸŸ¡ Medium |
| **C10** | SSE ä¸²æµå›æ‡‰ | `aiohttp` Server-Sent Events | ğŸŸ¡ Medium |
| **C11** | ä¸Šä¸‹æ–‡ç®¡ç† | å»ºæ§‹åŒ…å«éŒ¯èª¤ + å·¥ä½œæµä¸Šä¸‹æ–‡çš„ç³»çµ±æç¤º | ğŸŸ¢ Low |

#### æœªä¾†å¢å¼·ï¼ˆv2.1+ï¼‰

| ç·¨è™Ÿ | åŠŸèƒ½ | æè¿° | è¤‡é›œåº¦ |
|------|------|------|--------|
| **C12** | å°è©±æ­·å²æŒä¹…åŒ– | å„²å­˜/è¼‰å…¥å°è©±è¨˜éŒ„ | ğŸŸ¡ Medium |
| **C13** | åŒ¯å‡ºå°è©± | åŒ¯å‡ºç‚º Markdown/JSON | ğŸŸ¢ Low |
| **C14** | å¤šéŒ¯èª¤ä¸Šä¸‹æ–‡ | åœ¨åŒä¸€å°è©±ä¸­åƒè€ƒå¤šå€‹éŒ¯èª¤ | ğŸŸ¡ Medium |
| **C15** | ç¨‹å¼ç¢¼æ“ä½œ | é‡å°ç‰¹å®šå»ºè­°çš„ã€Œå¥—ç”¨ä¿®å¾©ã€æŒ‰éˆ• | ğŸ”´ High |

### 5.4 æŠ€è¡“é¸å‹

| å…ƒä»¶ | é¸æ“‡ | ç†ç”± |
|------|------|------|
| **Markdown æ¸²æŸ“** | marked.js (CDN) | è¼•é‡ï¼ˆ~40KB gzipï¼‰ã€é›¶ä¾è³´ |
| **ç¨‹å¼ç¢¼é«˜äº®** | highlight.js (CDN) | å»£æ³›èªè¨€æ”¯æ´ã€å¯æŒ‰éœ€è¼‰å…¥ |
| **ä¸²æµè§£æ** | åŸç”Ÿ EventSource | ç€è¦½å™¨å…§å»ºã€ç„¡é¡å¤–ä¾è³´ |
| **ç‹€æ…‹ç®¡ç†** | ç´” JavaScript Map/Array | ç¶­æŒé›¶ä¾è³´åŸå‰‡ |

### 5.5 API è¨­è¨ˆ

#### æ–°ç«¯é»ï¼š`POST /doctor/chat`

**è«‹æ±‚æ ¼å¼ï¼š**

```json
{
  "messages": [
    {"role": "user", "content": "ç‚ºä»€éº¼æœƒå‡ºç¾é€™å€‹ OOM éŒ¯èª¤ï¼Ÿ"},
    {"role": "assistant", "content": "æ ¹æ“šéŒ¯èª¤åˆ†æ..."},
    {"role": "user", "content": "å¦‚æœæˆ‘å·²ç¶“åœ¨ç”¨ --lowvram äº†å‘¢ï¼Ÿ"}
  ],
  "error_context": {
    "error": "RuntimeError: CUDA out of memory...",
    "node_context": {"node_id": "42", "node_name": "KSampler", ...}
  },
  "api_key": "sk-...",
  "base_url": "https://api.openai.com/v1",
  "model": "gpt-4o",
  "stream": true
}
```

**å›æ‡‰æ ¼å¼ï¼ˆSSEï¼‰ï¼š**

```
data: {"delta": "å¦‚æœ ", "done": false}
data: {"delta": "--lowvram ", "done": false}
data: {"delta": "ä»ç„¶ä¸å¤ ï¼Œå¯ä»¥å˜—è©¦ï¼š", "done": false}
data: {"delta": "", "done": true, "usage": {"prompt_tokens": 150, "completion_tokens": 89}}
```

### 5.6 æª”æ¡ˆçµæ§‹è®Šæ›´

```
web/
â”œâ”€â”€ doctor.js           # æ–°å¢ Chat è¨­å®šè¨»å†Š
â”œâ”€â”€ doctor_ui.js        # æ–°å¢ ChatPanel æ•´åˆ
â”œâ”€â”€ doctor_api.js       # æ–°å¢ streamChat() æ–¹æ³•
â”œâ”€â”€ doctor_chat.js      # ã€æ–°å¢ã€‘å°è©± UI å°ˆç”¨æ¨¡çµ„
â””â”€â”€ doctor_chat.css     # ã€æ–°å¢ã€‘å°è©±æ¨£å¼ï¼ˆæˆ–å…§åµŒï¼‰

__init__.py             # æ–°å¢ /doctor/chat ä¸²æµç«¯é»
```

### 5.7 å¯¦ä½œéšæ®µ

#### Phase 2.0-Aï¼šåŸºç¤å°è©±ï¼ˆ1-2 é€±ï¼‰

| ä»»å‹™ | ä¼°æ™‚ | ä¾è³´ |
|------|------|------|
| è¨­è¨ˆå°è©± UI æ¨£å¼ (CSS) | 2h | - |
| å¯¦ä½œ ChatPanel class | 4h | - |
| å¯¦ä½œè¨Šæ¯åˆ—è¡¨æ¸²æŸ“ | 3h | ChatPanel |
| æ•´åˆ marked.js + highlight.js | 2h | - |
| å¾Œç«¯ `/doctor/chat` ç«¯é»ï¼ˆéä¸²æµï¼‰| 3h | - |
| å‰å¾Œç«¯æ•´åˆæ¸¬è©¦ | 2h | ä»¥ä¸Šå…¨éƒ¨ |

#### Phase 2.0-Bï¼šä¸²æµèˆ‡é€²éšï¼ˆ1-2 é€±ï¼‰

| ä»»å‹™ | ä¼°æ™‚ | ä¾è³´ |
|------|------|------|
| å¾Œç«¯ SSE StreamResponse | 4h | - |
| å‰ç«¯ EventSource è§£æ | 3h | - |
| æ‰“å­—æ©Ÿæ•ˆæœå‹•ç•« | 2h | EventSource |
| é‡æ–°ç”ŸæˆåŠŸèƒ½ | 2h | - |
| å¿«é€Ÿè¿½å•æŒ‰éˆ• | 2h | - |
| ç¨‹å¼ç¢¼è¤‡è£½æŒ‰éˆ• | 1h | highlight.js |

#### Phase 2.0-Cï¼šå„ªåŒ–èˆ‡æ¸¬è©¦ï¼ˆ1 é€±ï¼‰

| ä»»å‹™ | ä¼°æ™‚ | ä¾è³´ |
|------|------|------|
| éŒ¯èª¤è™•ç†èˆ‡é‡è©¦æ©Ÿåˆ¶ | 2h | - |
| å°è©±æ­·å² Session ç®¡ç† | 2h | - |
| éŸ¿æ‡‰å¼è¨­è¨ˆï¼ˆå°è¢å¹•é©é…ï¼‰| 2h | - |
| å–®å…ƒæ¸¬è©¦ | 3h | - |
| æ–‡ä»¶æ›´æ–° | 2h | - |

### 5.8 æˆåŠŸæŒ‡æ¨™

| æŒ‡æ¨™ | ç›®æ¨™ |
|------|------|
| é¦–å‰‡è¨Šæ¯å›æ‡‰æ™‚é–“ | < 3 ç§’ï¼ˆä¸²æµé–‹å§‹ï¼‰|
| å°è©±é¢æ¿è¼‰å…¥æ™‚é–“ | < 500ms |
| Markdown æ¸²æŸ“æ™‚é–“ | < 100ms / è¨Šæ¯ |
| ä½¿ç”¨è€…æ»¿æ„åº¦ | > 80% æ­£é¢å›é¥‹ |

### 5.9 é¢¨éšªèˆ‡æ‡‰å°

| é¢¨éšª | å½±éŸ¿ | æ‡‰å°æªæ–½ |
|------|------|----------|
| Proxy ä¸æ”¯æ´ SSE | ä¸­ | é™ç´šç‚ºè¼ªè©¢æ¨¡å¼ |
| å¤§é‡ä¸Šä¸‹æ–‡è¶…é Token é™åˆ¶ | é«˜ | Token è¨ˆæ•¸ + æˆªæ–·ç­–ç•¥ |
| CDN ä¾è³´å¤±æ•ˆ | ä½ | æœ¬åœ°æ‰“åŒ…å‚™ç”¨ |
| LLM é™æµ | ä¸­ | æŒ‡æ•¸é€€é¿ + ä½¿ç”¨è€…é€šçŸ¥ |

---

## å…­ã€çµè«–

ç›®å‰å·²å…·å‚™å®Œæ•´çš„éŒ¯èª¤æ•ç²â†’åˆ†æâ†’å±•ç¤ºâ†’LLM è¼”åŠ©éˆè·¯ã€‚ä¸»è¦æ”¹é€²æ–¹å‘ç‚ºï¼š

1. **ç©©å¥æ€§**ï¼šåŠ å¼·éŒ¯èª¤è™•ç†ã€åŸ·è¡Œç·’å®‰å…¨ã€XSS é˜²è­· âœ… å·²å®Œæˆ
2. **å¯æ¸¬è©¦æ€§**ï¼šè£œé½Š API èˆ‡å‰ç«¯æ¸¬è©¦
3. **åŠŸèƒ½æ·±åº¦**ï¼šWorkflow ä¸Šä¸‹æ–‡æ•´åˆã€æ­·å²æŒä¹…åŒ–
4. **v2.0 æ ¸å¿ƒåŠŸèƒ½**ï¼šLLM é™¤éŒ¯å°è©±ä»‹é¢ï¼Œæä¾›å¤šè¼ªå°è©±å¼é™¤éŒ¯é«”é©— ğŸ†•
