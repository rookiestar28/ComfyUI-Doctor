# ComfyUI-Doctor Architecture & Extension Roadmap

[ç¹é«”ä¸­æ–‡](#comfyui-doctor-å°ˆæ¡ˆæž¶æ§‹èˆ‡æ“´å±•è¦åŠƒ) | English

## 1. Architecture

### 1.1 Core Module Structure

```mermaid
graph TD
    A[prestartup_script.py] -->|Early Hook| B[__init__.py]
    B --> C[logger.py]
    B --> D[analyzer.py]
    B --> E[i18n.py]
    B --> F[config.py]
    B --> G[nodes.py]

    C --> H[AsyncFileWriter]
    C --> I[SmartLogger]

    D --> J[ErrorAnalyzer]
    D --> K[NodeContext]

    B --> L[API Endpoints]
    L --> M["API: /debugger/last_analysis"]
    L --> N["API: /debugger/history"]
    L --> O["API: /debugger/set_language"]
    L --> P["API: /doctor/analyze"]
    L --> Q["API: /doctor/verify_key"]
    L --> R["API: /doctor/list_models"]
    L --> S["API: /doctor/provider_defaults"]

    T[web/doctor.js] --> U[Settings Registration]
    V[web/doctor_ui.js] --> W[Sidebar Panel]
    V --> X[Error Cards]
    V --> Y[AI Analysis]
    Z[web/doctor_api.js] --> AA[Fetch Wrapper]
```

### 1.2 Module Overview

| Module | Lines | Function |
|--------|-------|----------|
| `prestartup_script.py` | 102 | Earliest log interception hook (before custom_nodes load) |
| `__init__.py` | 891 | Main entry: full Logger install, 7 API endpoints, LLM integration, env var support |
| `logger.py` | 339 | Smart logger: async writes, real-time error analysis, history |
| `analyzer.py` | 271 | Error analyzer: 20+ error patterns, node context extraction |
| `i18n.py` | 190 | Internationalization: 9 languages (en, zh_TW, zh_CN, ja, de, fr, it, es, ko) |
| `config.py` | 65 | Config management: dataclass + JSON persistence |
| `nodes.py` | 179 | Smart Debug Node: deep data inspection |
| `doctor.js` | 600+ | ComfyUI settings panel integration, sidebar UI, chat interface |
| `doctor_ui.js` | 778 | Sidebar UI, error cards, AI analysis trigger |
| `doctor_api.js` | 207 | API wrapper layer with streaming support |

---

## 2. Robustness Assessment

### 2.1 Strengths âœ…

1. **Two-phase logging system** - `prestartup_script.py` ensures capture before all custom_nodes load
2. **Async I/O** - `AsyncFileWriter` uses background thread + batch writes, non-blocking
3. **Thread safety** - `threading.Lock` protects traceback buffer, `weakref.finalize` ensures cleanup
4. **Complete error analysis pipeline** - 20+ predefined patterns, regex LRU cache, node context extraction
5. **LLM integration** - Supports OpenAI/DeepSeek/Ollama/LMStudio with environment variable configuration
6. **Frontend integration** - Native ComfyUI Settings API, WebSocket `execution_error` subscription
7. **Internationalization** - 9 languages, extensible `SUGGESTIONS` structure
8. **Security hardening** - XSS protection, SSRF protection, markdown sanitization
9. **Cross-platform compatibility** - Environment variable support for local LLM URLs (Windows/WSL2/Docker)

### 2.2 Resolved Issues âœ…

#### Core Robustness (Phase 1)
- âœ… **R1**: Comprehensive error handling refactor
- âœ… **R2**: Thread safety hardening
- âœ… **R4**: XSS protection for AI analysis results

#### Resource Management (Phase 2)
- âœ… **R3**: aiohttp session reuse (SessionManager)
- âœ… **R8**: Smart workflow truncation for large graphs

#### Security Enhancements (Phase 3)
- âœ… **S2**: SSRF protection for Base URL validation
- âœ… **S4**: Sanitize chat markdown/HTML rendering (LLM + user output)
- âœ… **S5**: Bundle/pin markdown & highlight assets with local fallback

#### Streaming & Real-time (Phase 3)
- âœ… **R9**: SSE streaming chunk framing (buffer `data:` lines)
- âœ… **R10**: Hot-sync LLM settings for chat (API key/base URL/model)

#### Testing (Phase 1-3)
- âœ… **T1**: API endpoint unit tests
- âœ… **T6**: Fix test import issues (use `run_tests.ps1`)
- âœ… **T7**: SSE/chat safety tests (stream parser + sanitizer)

#### Features (Phase 2-3)
- âœ… **F1**: Error history persistence (SQLite/JSON)
- âœ… **F3**: Workflow context capture on error
- âœ… **F8**: Integrate settings panel into sidebar interface
- âœ… **F9**: Expand language support (de, fr, it, es, ko)

---

## 3. Extension Todo-List

### 3.1 Features (Pending)

- [ ] **F2**: Hot-reload error patterns from external JSON/YAML - ðŸŸ¢ Low
- [ ] **F4**: Error statistics dashboard - ðŸŸ¡ Medium âš ï¸ *Use dev branch*
- [ ] **F5**: Node health scoring - ðŸŸ¢ Low
- [ ] **F6**: Multi-LLM provider quick switch - ðŸŸ¡ Medium âš ï¸ *Use dev branch*
- [ ] **F7**: One-click auto-fix for specific errors - ðŸŸ¢ Low
- [x] **F10**: System environment context for AI analysis - ðŸŸ¡ Medium âœ… *Completed (2025-12-31)*
  - Capture Python version, installed packages (`pip list`), OS info
  - Include in `/doctor/analyze` and `/doctor/chat` payloads for better debugging
  - Cache package list with 24h TTL to avoid performance impact

### 3.2 Robustness (Pending)

- [ ] **R5**: Frontend error boundaries - ðŸŸ¡ Medium âš ï¸ *Use dev branch*
- [ ] **R6**: Network retry logic with exponential backoff - ðŸŸ¢ Low
- [ ] **R7**: Rate limiting for LLM API calls - ðŸŸ¢ Low
- [x] **R11**: Fix validation error capture to collect all failures - ðŸŸ¢ Low âœ… *Completed (2025-12-31)*
  - Modified logger to accumulate multiple "Failed to validate prompt" errors
  - Use "Executing prompt:" as completion marker instead of resetting buffer
  - Updated `is_complete_traceback()` to handle multi-error blocks

### 3.3 Testing (Pending)

- [ ] **T2**: Frontend interaction tests (Playwright) - ðŸŸ¡ Medium âš ï¸ *Use dev branch*
- [ ] **T3**: End-to-end integration tests - ðŸŸ¢ Low
- [ ] **T4**: Stress tests - ðŸŸ¢ Low
- [ ] **T5**: Online API integration tests (OpenAI, DeepSeek) - ðŸŸ¡ Medium

### 3.4 Security (Pending)

- [ ] **S1**: Add Content-Security-Policy headers - ðŸŸ¢ Low
- [ ] **S3**: Implement telemetry (opt-in, anonymous) - ðŸŸ¢ Low

### 3.5 Documentation (Pending)

- [ ] **D1**: OpenAPI/Swagger spec - ðŸŸ¡ Medium âš ï¸ *Use dev branch*
- [ ] **D2**: Architecture documentation - ðŸŸ¢ Low
- [ ] **D3**: Contribution guide - ðŸŸ¢ Low

### 3.6 Architecture Improvements (Pending)

*Sorted by complexity (simple â†’ complex):*

- [x] **A1**: Add `py.typed` marker + mypy config in pyproject.toml - ðŸŸ¢ Low âœ… *Completed (Phase 3A)*
- [x] **A2**: Integrate ruff linter (replace flake8/isort) - ðŸŸ¢ Low âœ… *Completed (Phase 3A)*
- [x] **A3**: Add pytest-cov with `--cov-report=term-missing` - ðŸŸ¢ Low âœ… *Completed (Phase 3A)*
- [ ] **A4**: Convert `NodeContext` to `@dataclass(frozen=True)` + validation - ðŸŸ¡ Medium âš ï¸ *Use dev branch*
- [ ] **A5**: Create `LLMProvider` Protocol for unified LLM interface - ðŸŸ¡ Medium âš ï¸ *Use dev branch*
- [ ] **A6**: Refactor analyzer.py to Pipeline pattern (captureâ†’parseâ†’classifyâ†’suggest) - ðŸ”´ High âš ï¸ *Use dev branch*

> [Note]
> Items marked with âš ï¸ should be developed on a separate `dev` branch. Merge to `main` only after thorough testing.

---

## 4. Development Phases

### Phase 1: Foundation & Robustness âœ… COMPLETED

**Focus**: Core stability and security

- âœ… **R1** Comprehensive error handling refactor
- âœ… **R2** Thread safety hardening
- âœ… **R4** XSS protection
- âœ… **T1** API endpoint unit tests

### Phase 2: Feature Enhancement âœ… COMPLETED

**Focus**: Workflow integration and persistence

- âœ… **F1** Error history persistence (SQLite/JSON)
- âœ… **F3** Workflow context capture on error
- âœ… **R3** aiohttp session reuse (SessionManager)
- âœ… **R8** Smart workflow truncation

### Phase 3: Production Hardening âœ… COMPLETED

**Focus**: Security, streaming, and UX

#### Phase 3A: Code Quality Tooling
- âœ… **A1-A3** Ruff linter, mypy, pytest-cov integration

#### Phase 3B: Security & Streaming
- âœ… **S2** SSRF protection
- âœ… **S4** Chat markdown sanitization
- âœ… **S5** Local asset bundling
- âœ… **R9** SSE streaming chunk framing
- âœ… **R10** Hot-sync LLM settings
- âœ… **T7** SSE/chat safety tests

#### Phase 3C: UX & Internationalization
- âœ… **F8** Sidebar settings integration
- âœ… **F9** Multi-language support (9 languages)
- âœ… **T6** Test infrastructure fixes

#### Phase 3D: Cross-Platform Support (2025-12-30)
- âœ… **Environment Variable Configuration** for local LLM URLs
  - `OLLAMA_BASE_URL` - Custom Ollama endpoint
  - `LMSTUDIO_BASE_URL` - Custom LMStudio endpoint
  - Prevents Windows/WSL2/Docker conflicts
  - Backend API `/doctor/provider_defaults` for dynamic URL loading
  - Frontend automatic provider defaults fetching

### Phase 4: Advanced Features (Planned)

**Focus**: Automation and extensibility

- [ ] **F2** Pattern hot-reload
- [ ] **F4** Statistics dashboard
- [ ] **F6** Multi-LLM provider quick switch
- [ ] **R6-R7** Network reliability improvements
- [ ] **T2-T5** Comprehensive testing suite

### Phase 5: Major Refactoring (Future)

**Focus**: Architecture optimization

- [ ] **A4-A6** Type safety and pipeline architecture
- [ ] **S1, S3** Advanced security features
- [ ] **D1-D3** Full documentation

---

## 5. v2.0 Major Feature: LLM Debug Chat Interface

> **Target Version**: v2.0.0
> **Status**: âœ… Core Features Complete
> **Priority**: ðŸ”´ High
> **Branch**: `main`
> **Last Updated**: 2025-12-30

### 5.1 Feature Overview

Transform single-shot analysis into a context-aware, multi-turn AI coding assistant with complete sidebar integration.

**Key Achievements**:
- âœ… Sidebar integration with proper flex layout
- âœ… Streaming chat with SSE
- âœ… Markdown rendering with syntax highlighting
- âœ… Real-time LLM settings synchronization
- âœ… Error context injection
- âœ… Security hardening (XSS, SSRF, sanitization)

### 5.2 Technical Stack

- **Frontend**: Vanilla JS (ES6+ Classes) - lightweight, React-like component structure
- **State**: Custom event-driven architecture
- **Transport**: Server-Sent Events (SSE) for reliable streaming
- **Rendering**: marked.js + highlight.js (local bundle with CDN fallback)
- **Security**: DOMPurify for sanitization, SSRF protection for URLs

### 5.3 Implementation Status

#### âœ… Completed Features
- Chat UI integrated into ComfyUI sidebar
- Streaming response with SSE
- Markdown + code highlighting
- One-click error analysis
- Multi-turn conversation support
- Settings hot-sync
- Security sanitization

#### ðŸš§ Future Enhancements
- [ ] Session persistence (localStorage)
- [ ] Quick action buttons (Explain Node, Optimize Workflow)
- [ ] Response regeneration
- [ ] Chat history export

### 5.4 API Design

**Endpoint**: `POST /doctor/chat`

**Request**:
```json
{
  "messages": [
    {"role": "user", "content": "Why this error?"},
    {"role": "assistant", "content": "Based on analysis..."},
    {"role": "user", "content": "How to fix?"}
  ],
  "error_context": {
    "error": "RuntimeError: CUDA out of memory...",
    "node_context": {"node_id": "42", ...},
    "workflow": {...}
  },
  "api_key": "sk-...",
  "base_url": "https://api.openai.com/v1",
  "model": "gpt-4o",
  "language": "zh_TW",
  "stream": true
}
```

**Response (SSE)**:
```
data: {"delta": "Based on ", "done": false}
data: {"delta": "the error ", "done": false}
data: {"delta": "analysis...", "done": false}
data: {"delta": "", "done": true}
```

---

## 6. Success Metrics

| Metric | Target | Current Status |
|--------|--------|----------------|
| Code coverage | > 80% | âœ… ~85% (with pytest-cov) |
| API response time | < 200ms | âœ… Achieved |
| Chat stream latency | < 3s to first token | âœ… Achieved |
| Security issues | 0 critical | âœ… All resolved |
| Supported languages | 5+ | âœ… 9 languages |
| Cross-platform support | Windows, Linux, macOS | âœ… Full support + WSL2 |

---

---

# ComfyUI-Doctor å°ˆæ¡ˆæž¶æ§‹èˆ‡æ“´å±•è¦åŠƒ

## ä¸€ã€å°ˆæ¡ˆæž¶æ§‹

### 1.1 æ ¸å¿ƒæ¨¡çµ„çµæ§‹

```mermaid
graph TD
    A[prestartup_script.py] -->|æ—©æœŸ Hook| B[__init__.py]
    B --> C[logger.py]
    B --> D[analyzer.py]
    B --> E[i18n.py]
    B --> F[config.py]
    B --> G[nodes.py]

    C --> H[AsyncFileWriter]
    C --> I[SmartLogger]

    D --> J[ErrorAnalyzer]
    D --> K[NodeContext]

    B --> L[API Endpoints]
    L --> M["API: /debugger/last_analysis"]
    L --> N["API: /debugger/history"]
    L --> O["API: /debugger/set_language"]
    L --> P["API: /doctor/analyze"]
    L --> Q["API: /doctor/verify_key"]
    L --> R["API: /doctor/list_models"]
    L --> S["API: /doctor/provider_defaults"]

    T[web/doctor.js] --> U[Settings Registration]
    V[web/doctor_ui.js] --> W[Sidebar Panel]
    V --> X[Error Cards]
    V --> Y[AI Analysis]
    Z[web/doctor_api.js] --> AA[Fetch Wrapper]
```

### 1.2 æ¨¡çµ„åŠŸèƒ½æ¦‚è¦½

| æ¨¡çµ„ | è¡Œæ•¸ | åŠŸèƒ½ |
|------|------|------|
| `prestartup_script.py` | 102 | æœ€æ—©çš„æ—¥èªŒæ””æˆª Hookï¼ˆåœ¨ custom_nodes è¼‰å…¥å‰ï¼‰ |
| `__init__.py` | 891 | ä¸»å…¥å£ï¼šå®Œæ•´ Logger å®‰è£ã€7 å€‹ API ç«¯é»žã€LLM æ•´åˆã€ç’°å¢ƒè®Šæ•¸æ”¯æ´ |
| `logger.py` | 339 | æ™ºèƒ½æ—¥èªŒå™¨ï¼šéžåŒæ­¥å¯«å…¥ã€éŒ¯èª¤å³æ™‚åˆ†æžã€æ­·å²è¨˜éŒ„ |
| `analyzer.py` | 271 | éŒ¯èª¤åˆ†æžå™¨ï¼š20+ éŒ¯èª¤æ¨¡å¼ã€ç¯€é»žä¸Šä¸‹æ–‡æ“·å– |
| `i18n.py` | 190 | åœ‹éš›åŒ–ï¼š9 èªžè¨€ï¼ˆen, zh_TW, zh_CN, ja, de, fr, it, es, koï¼‰ |
| `config.py` | 65 | é…ç½®ç®¡ç†ï¼šdataclass + JSON æŒä¹…åŒ– |
| `nodes.py` | 179 | Smart Debug Nodeï¼šæ·±åº¦æ•¸æ“šæª¢æŸ¥ |
| `doctor.js` | 600+ | ComfyUI è¨­å®šé¢æ¿æ•´åˆã€å´é‚Šæ¬„ UIã€èŠå¤©ä»‹é¢ |
| `doctor_ui.js` | 778 | Sidebar UIã€éŒ¯èª¤å¡ç‰‡ã€AI åˆ†æžè§¸ç™¼ |
| `doctor_api.js` | 207 | API å°è£å±¤ï¼ˆæ”¯æ´ä¸²æµï¼‰ |

---

## äºŒã€æž¶æ§‹å¼·å¥æ€§

### 2.1 å„ªé»ž âœ…

1. **é›™éšŽæ®µæ—¥èªŒç³»çµ±** - `prestartup_script.py` ç¢ºä¿åœ¨æ‰€æœ‰ custom_nodes è¼‰å…¥å‰å°±é–‹å§‹æ•ç²
2. **éžåŒæ­¥ I/O** - `AsyncFileWriter` ä½¿ç”¨èƒŒæ™¯åŸ·è¡Œç·’ + æ‰¹æ¬¡å¯«å…¥ï¼Œä¸é˜»å¡žä¸»åŸ·è¡Œç·’
3. **åŸ·è¡Œç·’å®‰å…¨** - `threading.Lock` ä¿è­· traceback bufferï¼Œ`weakref.finalize` ç¢ºä¿è³‡æºæ¸…ç†
4. **å®Œæ•´çš„éŒ¯èª¤åˆ†æžç®¡ç·š** - 20+ é å®šç¾©éŒ¯èª¤æ¨¡å¼ã€æ­£å‰‡è¡¨é”å¼ LRU å¿«å–ã€ç¯€é»žä¸Šä¸‹æ–‡æ“·å–
5. **LLM æ•´åˆæž¶æ§‹** - æ”¯æ´ OpenAI/DeepSeek/Ollama/LMStudioï¼Œç’°å¢ƒè®Šæ•¸é…ç½®
6. **å‰ç«¯æ•´åˆ** - åŽŸç”Ÿ ComfyUI Settings APIã€WebSocket `execution_error` è¨‚é–±
7. **åœ‹éš›åŒ–** - 9 èªžè¨€æ”¯æ´ï¼Œçµæ§‹åŒ–ç¿»è­¯å­—å…¸
8. **å®‰å…¨åŠ å›º** - XSS é˜²è­·ã€SSRF é˜²è­·ã€Markdown æ·¨åŒ–
9. **è·¨å¹³å°ç›¸å®¹** - ç’°å¢ƒè®Šæ•¸æ”¯æ´æœ¬åœ° LLM URLï¼ˆWindows/WSL2/Dockerï¼‰

### 2.2 å·²ä¿®å¾©å•é¡Œ âœ…

#### æ ¸å¿ƒç©©å¥æ€§ï¼ˆPhase 1ï¼‰
- âœ… **R1**: å…¨é¢çš„éŒ¯èª¤è™•ç†é‡æ§‹
- âœ… **R2**: åŸ·è¡Œç·’å®‰å…¨åŠ å›º
- âœ… **R4**: AI åˆ†æžçµæžœ XSS é˜²è­·

#### è³‡æºç®¡ç†ï¼ˆPhase 2ï¼‰
- âœ… **R3**: aiohttp Session è¤‡ç”¨ï¼ˆSessionManagerï¼‰
- âœ… **R8**: å¤§åž‹å·¥ä½œæµæ™ºèƒ½æˆªæ–·

#### å®‰å…¨æ€§å¢žå¼·ï¼ˆPhase 3ï¼‰
- âœ… **S2**: Base URL SSRF é˜²è­·
- âœ… **S4**: èŠå¤© Markdown/HTML æ¸²æŸ“æ·¨åŒ–
- âœ… **S5**: æœ¬åœ° bundle/éŽ–ç‰ˆ markdown & highlight è³‡æº

#### ä¸²æµèˆ‡å³æ™‚ï¼ˆPhase 3ï¼‰
- âœ… **R9**: SSE ä¸²æµåˆ†å¡Šé‡çµ„ï¼ˆç·©è¡ `data:` è¡Œï¼‰
- âœ… **R10**: èŠå¤© LLM è¨­å®šç†±åŒæ­¥

#### æ¸¬è©¦ï¼ˆPhase 1-3ï¼‰
- âœ… **T1**: API ç«¯é»žå–®å…ƒæ¸¬è©¦
- âœ… **T6**: ä¿®å¾©æ¸¬è©¦å°Žå…¥å•é¡Œï¼ˆä½¿ç”¨ `run_tests.ps1`ï¼‰
- âœ… **T7**: SSE/èŠå¤©å®‰å…¨æ¸¬è©¦

#### åŠŸèƒ½ï¼ˆPhase 2-3ï¼‰
- âœ… **F1**: éŒ¯èª¤æ­·å²æŒä¹…åŒ–ï¼ˆSQLite/JSONï¼‰
- âœ… **F3**: Workflow ä¸Šä¸‹æ–‡æ“·å–
- âœ… **F8**: è¨­å®šé¢æ¿æ•´åˆè‡³å´é‚Šæ¬„
- âœ… **F9**: æ“´å±•å¤šèªžç³»æ”¯æ´ï¼ˆde, fr, it, es, koï¼‰

---

## ä¸‰ã€å»¶ä¼¸æ“´å±•é …ç›®

### 3.1 åŠŸèƒ½æ“´å±•ï¼ˆå¾…å¯¦ä½œï¼‰

- [ ] **F2**: éŒ¯èª¤æ¨¡å¼ç†±æ›´æ–°ï¼ˆå¾žå¤–éƒ¨ JSON/YAML è¼‰å…¥ï¼‰ - ðŸŸ¢ Low
- [ ] **F4**: éŒ¯èª¤çµ±è¨ˆå„€è¡¨æ¿ - ðŸŸ¡ Medium âš ï¸ *ä½¿ç”¨ dev branch*
- [ ] **F5**: ç¯€é»žå¥åº·è©•åˆ† - ðŸŸ¢ Low
- [ ] **F6**: å¤š LLM Provider å¿«é€Ÿåˆ‡æ› - ðŸŸ¡ Medium âš ï¸ *ä½¿ç”¨ dev branch*
- [ ] **F7**: éŒ¯èª¤è‡ªå‹•ä¿®å¾©å»ºè­°åŸ·è¡Œï¼ˆä¸€éµä¿®å¾©ï¼‰ - ðŸŸ¢ Low
- [x] **F10**: AI åˆ†æžçš„ç³»çµ±ç’°å¢ƒä¸Šä¸‹æ–‡ - ðŸŸ¡ Medium âœ… *å·²å®Œæˆ (2025-12-31)*
  - æ•æ‰ Python ç‰ˆæœ¬ã€å·²å®‰è£å¥—ä»¶ï¼ˆ`pip list`ï¼‰ã€ä½œæ¥­ç³»çµ±è³‡è¨Š
  - åœ¨ `/doctor/analyze` å’Œ `/doctor/chat` è«‹æ±‚ä¸­åŒ…å«ç’°å¢ƒè³‡è¨Šä»¥æå‡åµéŒ¯æº–ç¢ºåº¦
  - å¥—ä»¶åˆ—è¡¨å¿«å–ï¼ˆ24å°æ™‚ TTLï¼‰é¿å…æ•ˆèƒ½å½±éŸ¿

### 3.2 ç©©å¥æ€§æ”¹é€²ï¼ˆå¾…å¯¦ä½œï¼‰

- [ ] **R5**: å‰ç«¯éŒ¯èª¤é‚Šç•Œ - ðŸŸ¡ Medium âš ï¸ *ä½¿ç”¨ dev branch*
- [ ] **R6**: ç¶²è·¯é‡è©¦é‚è¼¯ï¼ˆexponential backoffï¼‰ - ðŸŸ¢ Low
- [ ] **R7**: LLM API å‘¼å«é€ŸçŽ‡é™åˆ¶ - ðŸŸ¢ Low
- [x] **R11**: ä¿®æ­£é©—è­‰éŒ¯èª¤æ•ç²ä»¥æ”¶é›†æ‰€æœ‰å¤±æ•—é …ç›® - ðŸŸ¢ Low âœ… *å·²å®Œæˆ (2025-12-31)*
  - ä¿®æ”¹ logger ç´¯ç©å¤šå€‹ "Failed to validate prompt" éŒ¯èª¤
  - ä½¿ç”¨ "Executing prompt:" ä½œç‚ºå®Œæˆæ¨™è¨˜è€Œéžé‡ç½®ç·©è¡å€
  - æ›´æ–° `is_complete_traceback()` è™•ç†å¤šéŒ¯èª¤å€å¡Š

### 3.3 æ¸¬è©¦æ“´å……ï¼ˆå¾…å¯¦ä½œï¼‰

- [ ] **T2**: å‰ç«¯äº’å‹•æ¸¬è©¦ï¼ˆPlaywrightï¼‰ - ðŸŸ¡ Medium âš ï¸ *ä½¿ç”¨ dev branch*
- [ ] **T3**: ç«¯å°ç«¯æ•´åˆæ¸¬è©¦ - ðŸŸ¢ Low
- [ ] **T4**: å£“åŠ›æ¸¬è©¦ - ðŸŸ¢ Low
- [ ] **T5**: ç·šä¸Š API æ•´åˆæ¸¬è©¦ï¼ˆOpenAIã€DeepSeekï¼‰ - ðŸŸ¡ Medium

### 3.4 å®‰å…¨æ€§ï¼ˆå¾…å¯¦ä½œï¼‰

- [ ] **S1**: Content-Security-Policy æ¨™é ­ - ðŸŸ¢ Low
- [ ] **S3**: é™æ¸¬æ•¸æ“šæ”¶é›†ï¼ˆåŒ¿åã€å¯é¸ï¼‰ - ðŸŸ¢ Low

### 3.5 æ–‡ä»¶ï¼ˆå¾…å¯¦ä½œï¼‰

- [ ] **D1**: OpenAPI/Swagger è¦æ ¼æ–‡ä»¶ - ðŸŸ¡ Medium âš ï¸ *ä½¿ç”¨ dev branch*
- [ ] **D2**: æž¶æ§‹æ–‡ä»¶ - ðŸŸ¢ Low
- [ ] **D3**: è²¢ç»æŒ‡å— - ðŸŸ¢ Low

### 3.6 æž¶æ§‹æ”¹é€²ï¼ˆå¾…å¯¦ä½œï¼‰

*æŒ‰è¤‡é›œåº¦æŽ’åºï¼ˆç°¡å–® â†’ è¤‡é›œï¼‰ï¼š*

- [x] **A1**: py.typed + mypy é…ç½® - ðŸŸ¢ Low âœ… *å·²æ–¼ Phase 3A å®Œæˆ*
- [x] **A2**: æ•´åˆ ruff linter - ðŸŸ¢ Low âœ… *å·²æ–¼ Phase 3A å®Œæˆ*
- [x] **A3**: pytest-cov è¦†è“‹çŽ‡å ±å‘Š - ðŸŸ¢ Low âœ… *å·²æ–¼ Phase 3A å®Œæˆ*
- [ ] **A4**: NodeContext æ”¹ç‚º frozen dataclass - ðŸŸ¡ Medium âš ï¸ *ä½¿ç”¨ dev branch*
- [ ] **A5**: å»ºç«‹ LLMProvider Protocol - ðŸŸ¡ Medium âš ï¸ *ä½¿ç”¨ dev branch*
- [ ] **A6**: é‡æ§‹ analyzer.py ç‚º Pipeline æž¶æ§‹ - ðŸ”´ High âš ï¸ *ä½¿ç”¨ dev branch*

> [æ³¨æ„]
> æ¨™è¨» âš ï¸ çš„é …ç›®æ‡‰åœ¨ç¨ç«‹çš„ `dev` åˆ†æ”¯ä¸Šé–‹ç™¼ï¼Œå®Œæˆå……åˆ†æ¸¬è©¦å¾Œå†åˆä½µè‡³ `main`ã€‚

---

## å››ã€é–‹ç™¼éšŽæ®µ

### Phase 1: åŸºç¤Žèˆ‡ç©©å¥æ€§ âœ… å·²å®Œæˆ

**é‡é»ž**: æ ¸å¿ƒç©©å®šæ€§èˆ‡å®‰å…¨æ€§

- âœ… **R1** å…¨é¢çš„éŒ¯èª¤è™•ç†é‡æ§‹
- âœ… **R2** åŸ·è¡Œç·’å®‰å…¨åŠ å›º
- âœ… **R4** XSS é˜²è­·
- âœ… **T1** API ç«¯é»žå–®å…ƒæ¸¬è©¦

### Phase 2: åŠŸèƒ½å¢žå¼· âœ… å·²å®Œæˆ

**é‡é»ž**: Workflow æ•´åˆèˆ‡æŒä¹…åŒ–

- âœ… **F1** éŒ¯èª¤æ­·å²æŒä¹…åŒ–ï¼ˆSQLite/JSONï¼‰
- âœ… **F3** Workflow ä¸Šä¸‹æ–‡æ“·å–
- âœ… **R3** aiohttp Session è¤‡ç”¨ï¼ˆSessionManagerï¼‰
- âœ… **R8** å¤§åž‹å·¥ä½œæµæ™ºèƒ½æˆªæ–·

### Phase 3: ç”Ÿç”¢ç’°å¢ƒåŠ å›º âœ… å·²å®Œæˆ

**é‡é»ž**: å®‰å…¨æ€§ã€ä¸²æµèˆ‡ UX

#### Phase 3A: ç¨‹å¼ç¢¼å“è³ªå·¥å…·
- âœ… **A1-A3** Ruff linterã€mypyã€pytest-cov æ•´åˆ

#### Phase 3B: å®‰å…¨æ€§èˆ‡ä¸²æµ
- âœ… **S2** SSRF é˜²è­·
- âœ… **S4** èŠå¤© Markdown æ·¨åŒ–
- âœ… **S5** æœ¬åœ°è³‡æº bundle
- âœ… **R9** SSE ä¸²æµåˆ†å¡Šé‡çµ„
- âœ… **R10** LLM è¨­å®šç†±åŒæ­¥
- âœ… **T7** SSE/èŠå¤©å®‰å…¨æ¸¬è©¦

#### Phase 3C: UX èˆ‡åœ‹éš›åŒ–
- âœ… **F8** å´é‚Šæ¬„è¨­å®šæ•´åˆ
- âœ… **F9** å¤šèªžç³»æ”¯æ´ï¼ˆ9 èªžè¨€ï¼‰
- âœ… **T6** æ¸¬è©¦åŸºç¤Žè¨­æ–½ä¿®å¾©

#### Phase 3D: è·¨å¹³å°æ”¯æ´ï¼ˆ2025-12-30ï¼‰
- âœ… **ç’°å¢ƒè®Šæ•¸é…ç½®**æœ¬åœ° LLM URL
  - `OLLAMA_BASE_URL` - è‡ªè¨‚ Ollama ç«¯é»ž
  - `LMSTUDIO_BASE_URL` - è‡ªè¨‚ LMStudio ç«¯é»ž
  - é˜²æ­¢ Windows/WSL2/Docker è¡çª
  - å¾Œç«¯ API `/doctor/provider_defaults` å‹•æ…‹ URL è¼‰å…¥
  - å‰ç«¯è‡ªå‹•ç²å– provider é è¨­å€¼

### Phase 4: é€²éšŽåŠŸèƒ½ï¼ˆè¦åŠƒä¸­ï¼‰

**é‡é»ž**: è‡ªå‹•åŒ–èˆ‡å¯æ“´å±•æ€§

- [ ] **F2** æ¨¡å¼ç†±æ›´æ–°
- [ ] **F4** çµ±è¨ˆå„€è¡¨æ¿
- [ ] **F6** å¤š LLM Provider å¿«é€Ÿåˆ‡æ›
- [ ] **R6-R7** ç¶²è·¯å¯é æ€§æ”¹é€²
- [ ] **T2-T5** å…¨é¢æ¸¬è©¦å¥—ä»¶

### Phase 5: é‡å¤§é‡æ§‹ï¼ˆæœªä¾†ï¼‰

**é‡é»ž**: æž¶æ§‹å„ªåŒ–

- [ ] **A4-A6** åž‹åˆ¥å®‰å…¨èˆ‡ Pipeline æž¶æ§‹
- [ ] **S1, S3** é€²éšŽå®‰å…¨åŠŸèƒ½
- [ ] **D1-D3** å®Œæ•´æ–‡ä»¶

---

## äº”ã€v2.0 é‡å¤§åŠŸèƒ½ï¼šLLM é™¤éŒ¯å°è©±ä»‹é¢

> **ç›®æ¨™ç‰ˆæœ¬**ï¼šv2.0.0
> **ç‹€æ…‹**ï¼šâœ… æ ¸å¿ƒåŠŸèƒ½å®Œæˆ
> **å„ªå…ˆç´š**ï¼šðŸ”´ High
> **åˆ†æ”¯**ï¼š`main`
> **æœ€å¾Œæ›´æ–°**ï¼š2025-12-30

### 5.1 åŠŸèƒ½æ¦‚è¿°

å°‡å–®æ¬¡ AI åˆ†æžå‡ç´šç‚ºå®Œæ•´çš„å°è©±å¼é™¤éŒ¯é«”é©—ï¼Œå®Œæ•´æ•´åˆè‡³å´é‚Šæ¬„ã€‚

**ä¸»è¦æˆå°±**:
- âœ… å´é‚Šæ¬„æ•´åˆï¼ˆæ­£ç¢ºçš„ flex ä½ˆå±€ï¼‰
- âœ… SSE ä¸²æµèŠå¤©
- âœ… Markdown æ¸²æŸ“èˆ‡èªžæ³•é«˜äº®
- âœ… å³æ™‚ LLM è¨­å®šåŒæ­¥
- âœ… éŒ¯èª¤ä¸Šä¸‹æ–‡æ³¨å…¥
- âœ… å®‰å…¨åŠ å›ºï¼ˆXSSã€SSRFã€æ·¨åŒ–ï¼‰

### 5.2 æŠ€è¡“å †ç–Š

- **å‰ç«¯**: Vanilla JS (ES6+ Classes) - è¼•é‡ã€React-like çµ„ä»¶çµæ§‹
- **ç‹€æ…‹**: è‡ªè¨‚äº‹ä»¶é©…å‹•æž¶æ§‹
- **å‚³è¼¸**: Server-Sent Events (SSE) å¯é ä¸²æµ
- **æ¸²æŸ“**: marked.js + highlight.jsï¼ˆæœ¬åœ° bundle + CDN fallbackï¼‰
- **å®‰å…¨**: DOMPurify æ·¨åŒ–ã€SSRF URL é˜²è­·

### 5.3 å¯¦ä½œç‹€æ…‹

#### âœ… å·²å®ŒæˆåŠŸèƒ½
- èŠå¤© UI æ•´åˆè‡³ ComfyUI å´é‚Šæ¬„
- SSE ä¸²æµå›žæ‡‰
- Markdown + ç¨‹å¼ç¢¼é«˜äº®
- ä¸€éµéŒ¯èª¤åˆ†æž
- å¤šè¼ªå°è©±æ”¯æ´
- è¨­å®šç†±åŒæ­¥
- å®‰å…¨æ·¨åŒ–

#### ðŸš§ æœªä¾†å¢žå¼·
- [ ] Session æŒä¹…åŒ–ï¼ˆlocalStorageï¼‰
- [ ] å¿«é€Ÿæ“ä½œæŒ‰éˆ•ï¼ˆè§£é‡‹ç¯€é»žã€å„ªåŒ–å·¥ä½œæµï¼‰
- [ ] å›žæ‡‰é‡æ–°ç”Ÿæˆ
- [ ] èŠå¤©æ­·å²åŒ¯å‡º

### 5.4 API è¨­è¨ˆ

**ç«¯é»ž**: `POST /doctor/chat`

**è«‹æ±‚**:
```json
{
  "messages": [
    {"role": "user", "content": "ç‚ºä»€éº¼æœƒé€™å€‹éŒ¯èª¤ï¼Ÿ"},
    {"role": "assistant", "content": "æ ¹æ“šåˆ†æž..."},
    {"role": "user", "content": "å¦‚ä½•ä¿®å¾©ï¼Ÿ"}
  ],
  "error_context": {
    "error": "RuntimeError: CUDA out of memory...",
    "node_context": {"node_id": "42", ...},
    "workflow": {...}
  },
  "api_key": "sk-...",
  "base_url": "https://api.openai.com/v1",
  "model": "gpt-4o",
  "language": "zh_TW",
  "stream": true
}
```

**å›žæ‡‰ï¼ˆSSEï¼‰**:
```
data: {"delta": "æ ¹æ“š ", "done": false}
data: {"delta": "éŒ¯èª¤ ", "done": false}
data: {"delta": "åˆ†æž...", "done": false}
data: {"delta": "", "done": true}
```

---

## å…­ã€æˆåŠŸæŒ‡æ¨™

| æŒ‡æ¨™ | ç›®æ¨™ | ç›®å‰ç‹€æ…‹ |
|------|------|----------|
| ç¨‹å¼ç¢¼è¦†è“‹çŽ‡ | > 80% | âœ… ~85%ï¼ˆä½¿ç”¨ pytest-covï¼‰ |
| API å›žæ‡‰æ™‚é–“ | < 200ms | âœ… å·²é”æˆ |
| èŠå¤©ä¸²æµå»¶é² | < 3s è‡³ç¬¬ä¸€å€‹ token | âœ… å·²é”æˆ |
| å®‰å…¨æ€§å•é¡Œ | 0 critical | âœ… å…¨éƒ¨è§£æ±º |
| æ”¯æ´èªžè¨€æ•¸ | 5+ | âœ… 9 èªžè¨€ |
| è·¨å¹³å°æ”¯æ´ | Windows, Linux, macOS | âœ… å®Œæ•´æ”¯æ´ + WSL2 |

---
