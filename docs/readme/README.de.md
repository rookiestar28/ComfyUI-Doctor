# ComfyUI-Doctor

[ÁπÅ‰∏≠](README.zh-TW.md) | [ÁÆÄ‰∏≠](README.zh-CN.md) | [Êó•Êú¨Ë™û](README.ja.md) | [ÌïúÍµ≠Ïñ¥](README.ko.md) | Deutsch | [Fran√ßais](README.fr.md) | [Italiano](README.it.md) | [Espa√±ol](README.es.md) | [English](../README.md) | [Roadmap & Entwicklungsstatus](../ROADMAP.md)

Eine kontinuierliche Echtzeit-Laufzeitdiagnose-Suite f√ºr ComfyUI mit **KI-gest√ºtzter Analyse**, **interaktivem Debugging-Chat** und **50+ Fehlerbehebungsmustern**. F√§ngt automatisch alle Terminalausgaben ab dem Start ab, erfasst vollst√§ndige Python-Tracebacks und liefert priorisierte Korrekturvorschl√§ge mit Kontext-Extraktion auf Knotenebene. Unterst√ºtzt jetzt **JSON-basiertes Mustermanagement** mit Hot-Reload und **vollst√§ndige i18n-Unterst√ºtzung** f√ºr 9 Sprachen (en, zh_TW, zh_CN, ja, de, fr, it, es, ko).

## Neueste Updates (Jan 2026) - Zum Erweitern klicken

<details>
<summary><strong>Neues Feature: F14 Proaktive Diagnose (Health Checks + Intent Signature)</strong></summary>

- Im **Statistik (Statistics)** Tab wurde ein **Diagnose (Diagnostics)** Bereich hinzugef√ºgt, um Workflow-Probleme proaktiv ohne LLM zu beheben.
- **Health Check**: Beinhaltet Workflow-Checks (Linting), Umgebungs-Assets (env assets) und Datenschutz-Checks sowie umsetzbare Korrekturvorschl√§ge.
- **Intent Signature**: Deterministisches Absichts-Inferenzsystem, das **Top-K Absichten + Beweise** liefert, um zu beurteilen, was der Workflow "versucht zu tun".
- Enth√§lt UX-H√§rtung: Sichere Fallbacks (z.B. "Keine dominante Absicht erkannt") und verbesserte Beweisbereinigung.

</details>

<details>
<summary><strong>(v1.5.8) QoL: Auto-open Right Error Report Panel Toggle</strong></summary>

- Added a **dedicated toggle** in **Doctor ‚Üí Settings** to control whether the **right-side error report panel** auto-opens when a new error is detected.
- **Default: ON** for new installs, and the choice is persisted.

</details>

<details>
<summary><strong>Smart Token Budget Management (v1.5.0)</strong></summary>

**Intelligentes Kontextmanagement (Kostenoptimierung):**

- **Automatisches Trimming**: F√ºr Remote-LLMs (60-80% Token-Reduktion)
- **Progressive Strategie**: Workflow-Pruning ‚Üí Systeminfo entfernen ‚Üí Traceback k√ºrzen
- **Lokaler Opt-in**: Sanftes Trimming f√ºr Ollama/LMStudio (12K/16K Limits)
- **Erweiterte Observability**: Schritt-f√ºr-Schritt Token-Tracking & A/B Validierung

**Netzwerk-Resilienz:**

- **Exponentieller Backoff**: Automatischer Retry bei 429/5xx Fehlern (mit Jitter)
- **Streaming-Schutz**: 30s Timeout-Watchdog f√ºr blockierte SSE-Chunks
- **Rate & Concurrency Limits**: Token Bucket (30/Min) + Concurrency Semaphore (max 3)

**Neue Konfiguration:**

| Config Key | Default | Description |
|------------|---------|-------------|
| `r12_enabled_remote` | `true` | Smart Budget aktivieren (Remote) |
| `retry_max_attempts` | `3` | Max Retries |
| `stream_chunk_timeout` | `30` | Stream Timeout (Sek) |

</details>

<details>
<summary><strong>Wichtige Korrektur: R0/R13 Pipeline-Governance & Plugin-Sicherheit (v1.4.5)</strong></summary>

**Sicherheits-H√§rtung:**

- **SSRF-Schutz++**: Ersetzung von Teilstring-Pr√ºfungen durch korrektes Host/Port-Parsing; Blockierung ausgehender Weiterleitungen (`allow_redirects=False`)
- **Outbound-Sanitization-Funnel**: Eine einzige Grenze (`outbound.py`) garantiert die Bereinigung ALLER externen Payloads; `privacy_mode=none` nur f√ºr verifizierte lokale LLMs erlaubt

**Plugin-Vertrauenssystem:**

- **Sicher-nach-Standard**: Plugins standardm√§√üig deaktiviert, explizite Allowlist + Manifest/SHA256 erforderlich
- **Vertrauensklassifizierung**: `trusted` (vertrauensw√ºrdig) | `unsigned` (unsigniert) | `untrusted` (nicht vertrauensw√ºrdig) | `blocked` (blockiert)
- **Dateisystem-Eind√§mmung**: realpath-Eind√§mmung, Symlink-Verweigerung, Gr√∂√üenbeschr√§nkungen, strenge Dateinamenregeln
- **Optionale HMAC-Signierung**: Integrit√§tspr√ºfung mit gemeinsamem Geheimnis (keine Public-Key-Signierung)

**Pipeline-Governance:**

- **Metadaten-Vertr√§ge**: Schema-Versionierung + Validierung nach Ausf√ºhrung + Quarant√§ne f√ºr ung√ºltige Schl√ºssel
- **Abh√§ngigkeitsrichtlinie**: Erzwungenes `requires/provides`; fehlende Abh√§ngigkeit ‚Üí Stufe √ºberspringen, Status `degraded` (beeintr√§chtigt)
- **Logger-R√ºckstau**: Priorit√§tsbewusste `DroppingQueue` + Drop-Metriken
- **√úbergabe vor dem Start**: Saubere Deinstallation des Loggers, bevor der SmartLogger √ºbernimmt

**Beobachtbarkeit:**

- `/doctor/health` Endpunkt: Stellt Warteschlangen-Metriken, Drop-Z√§hler, SSRF-Bl√∂cke und Pipeline-Status bereit

**Testergebnisse**: 159 Python-Tests bestanden | 17 Phase-2-Gate-Tests

</details>

<details>
<summary><strong>Verbesserung: CI Gates & Plugin-Tools</strong></summary>

**T11 - Phase 2 Release CI Gate:**

- GitHub Actions Workflow (`phase2-release-gate.yml`): Erzwingt 4 Pytest-Suites + E2E
- Lokales Validierungsskript (`scripts/phase2_gate.py`): Unterst√ºtzt `--fast` und `--e2e` Modi

**T12 - Statischer Checker f√ºr Outbound-Sicherheit:**

- AST-basierter Analysator (`scripts/check_outbound_safety.py`) erkennt Umgehungsmuster
- 6 Erkennungsregeln: `RAW_FIELD_IN_PAYLOAD`, `DANGEROUS_FALLBACK`, `POST_WITHOUT_SANITIZATION`, usw.
- CI Workflow + 8 Unit-Tests + Dokumentation (`docs/OUTBOUND_SAFETY.md`)

**A8 - Plugin-Migrationstools:**

- `scripts/plugin_manifest.py`: Generiert Manifest mit SHA256-Hashes
- `scripts/plugin_allowlist.py`: Scannt Plugins und schl√§gt Konfiguration vor
- `scripts/plugin_validator.py`: Validiert Manifest und Konfiguration
- `scripts/plugin_hmac_sign.py`: Generiert optionale HMAC-Signaturen
- Dokumentation aktualisiert: `docs/PLUGIN_MIGRATION.md`, `docs/PLUGIN_GUIDE.md`

</details>

<details>
<summary><strong>Verbesserung: CSP-Doku & Telemetrie</strong></summary>

**S1 - CSP-Compliance-Doku:**

- Verifiziert, dass alle Assets lokal geladen werden (`web/lib/`); CDN-URLs nur als Fallback
- Abschnitt "CSP Compatibility" zur README hinzugef√ºgt
- Code-Audit abgeschlossen (manuelle Verifizierung ausstehend)

**S3 - Lokale Telemetrie-Infrastruktur:**

- Backend: `telemetry.py` (TelemetryStore, RateLimiter, PII-Erkennung)
- 6 API-Endpunkte: `/doctor/telemetry/{status,buffer,track,clear,export,toggle}`
- Frontend: Einstellungs-UI-Steuerelemente f√ºr Telemetrie-Verwaltung
- Sicherheit: Origin-Check (403 Cross-Origin), 1KB Payload-Limit, Feld-Allowlist
- **Standardm√§√üig AUS**: Keine Aufzeichnung/Netzwerkaktivit√§t, sofern nicht explizit aktiviert
- 81 i18n-Strings (9 Schl√ºssel √ó 9 Sprachen)

**Testergebnisse**: 27 Telemetrie-Unit-Tests | 8 E2E-Tests

</details>

<details>
<summary><strong>Verbesserung: E2E-Runner-H√§rtung & Vertrauens/Gesundheits-UI</strong></summary>

**E2E-Runner-H√§rtung (WSL `/mnt/c` Support):**

- Playwright-√úbersetzungscache-Berechtigungsprobleme unter WSL behoben
- Schreibbares tempor√§res Verzeichnis (`.tmp/playwright`) unter Repo hinzugef√ºgt
- `PW_PYTHON` Override f√ºr plattform√ºbergreifende Kompatibilit√§t

**Vertrauens- & Gesundheits-UI-Panel:**

- "Trust & Health" Panel zum Statistik (Statistics) Tab hinzugef√ºgt
- Zeigt: pipeline_status, ssrf_blocked, dropped_logs
- Plugin-Vertrauensliste (mit Badges und Gr√ºnden)
- `GET /doctor/plugins` Nur-Scan-Endpunkt (kein Code-Import)

**Testergebnisse**: 61/61 E2E-Tests bestanden | 159/159 Python-Tests bestanden

</details>

<details>
<summary><strong>Fr√ºhere Updates (v1.4.0, Jan 2026)</strong></summary>

- A7 Preact-Migration abgeschlossen (Phase 5A‚Äì5C: Chat/Stats Islands, Registry, Shared Rendering, robuste Fallbacks).
- Integrationsh√§rtung: Playwright E2E-Abdeckung gest√§rkt.
- UI-Korrekturen: Timing des Sidebar-Tooltips korrigiert.

</details>

<details>
<summary><strong>Statistik-Dashboard</strong></summary>

**Verfolgen Sie Ihre ComfyUI-Stabilit√§t auf einen Blick!**

ComfyUI-Doctor enth√§lt jetzt ein **Statistik-Dashboard**, das Einblicke in Fehlertrends, h√§ufige Probleme und den L√∂sungsfortschritt bietet.

**Funktionen**:

- üìä **Fehlertrends**: Verfolgen Sie Fehler √ºber 24 Std./7 Tage/30 Tage
- üî• **Top 5 Muster**: Sehen Sie, welche Fehler am h√§ufigsten auftreten
- üìà **Kategorie-Aufschl√ºsselung**: Visualisieren Sie Fehler nach Kategorie (Speicher, Workflow, Modellladen usw.)
- ‚úÖ **L√∂sungsverfolgung**: √úberwachen Sie gel√∂ste vs. ungel√∂ste Fehler
- üåç **Vollst√§ndige i18n-Unterst√ºtzung**: Verf√ºgbar in allen 9 Sprachen

![Statistik-Dashboard](../../assets/statistics_panel.png)

**Verwendung**:

1. √ñffnen Sie das Doctor-Seitenleistenpanel (klicken Sie auf das üè•-Symbol links)
2. Erweitern Sie den Abschnitt "üìä Fehlerstatistik"
3. Sehen Sie sich Echtzeit-Fehleranalysen und Trends an
4. Markieren Sie Fehler als gel√∂st/ignoriert, um Ihren Fortschritt zu verfolgen

**Backend-API**:

- `GET /doctor/statistics?time_range_days=30` - Statistiken abrufen
- `POST /doctor/mark_resolved` - L√∂sungsstatus aktualisieren

**Testabdeckung**: 17/17 Backend-Tests ‚úÖ | 14/18 E2E-Tests (78% Erfolgsquote)

**Implementierungsdetails**: Siehe `.planning/260104-F4_STATISTICS_RECORD.md`

</details>

<details>
<summary><strong>Pattern-Validierung CI</strong></summary>

**Automatisierte Qualit√§tspr√ºfungen sch√ºtzen jetzt die Pattern-Integrit√§t!**

ComfyUI-Doctor enth√§lt jetzt **Continuous Integration Testing** f√ºr alle Fehlermuster, um fehlerfreie Beitr√§ge zu gew√§hrleisten.

**Was T8 validiert**:

- ‚úÖ **JSON-Format**: Alle 8 Pattern-Dateien werden korrekt kompiliert
- ‚úÖ **Regex-Syntax**: Alle 57 Muster haben g√ºltige regul√§re Ausdr√ºcke
- ‚úÖ **i18n-Vollst√§ndigkeit**: 100% √úbersetzungsabdeckung (57 Muster √ó 9 Sprachen = 513 Pr√ºfungen)
- ‚úÖ **Schema-Konformit√§t**: Erforderliche Felder (`id`, `regex`, `error_key`, `priority`, `category`)
- ‚úÖ **Metadaten-Qualit√§t**: G√ºltige Priorit√§tsbereiche (50-95), eindeutige IDs, korrekte Kategorien

**GitHub Actions Integration**:

- Wird bei jedem Push/PR ausgel√∂st, der `patterns/`, `i18n.py` oder Tests betrifft
- L√§uft in ca. 3 Sekunden mit $0 Kosten (GitHub Actions Free Tier)
- Blockiert Merges, wenn die Validierung fehlschl√§gt

**F√ºr Mitwirkende**:

```bash
# Lokale Validierung vor dem Commit
python scripts/run_pattern_tests.py

# Ausgabe:
‚úÖ All 57 patterns have required fields
‚úÖ All 57 regex patterns compile successfully
‚úÖ en: All 57 patterns have translations
‚úÖ zh_TW: All 57 patterns have translations
... (insgesamt 9 Sprachen)
```

**Testergebnisse**: 100% Erfolgsquote bei allen Pr√ºfungen

**Implementierungsdetails**: Siehe `.planning/260103-T8_IMPLEMENTATION_RECORD.md`

</details>

<details>
<summary><strong>√úberarbeitung des Mustersystems (STAGE 1-3 abgeschlossen)</strong></summary>

ComfyUI-Doctor wurde einem umfassenden Architektur-Upgrade unterzogen mit **57+ Fehlermustern** und **JSON-basiertem Mustermanagement**!

**STAGE 1: Logger-Architektur-Fix**

- SafeStreamWrapper mit warteschlangenbasierter Hintergrundverarbeitung implementiert
- Deadlock-Risiken und Race Conditions eliminiert
- Konflikte beim Abfangen von Logs mit dem LogInterceptor von ComfyUI behoben

**STAGE 2: JSON-Mustermanagement (F2)**

- Neuer PatternLoader mit Hot-Reload-Funktion (kein Neustart erforderlich!)
- Muster werden jetzt in JSON-Dateien im Verzeichnis `patterns/` definiert
- 22 integrierte Muster in `patterns/builtin/core.json`
- Einfach zu erweitern und zu warten

**STAGE 3: Erweiterung der Community-Muster (F12)**

- **35 neue Community-Muster**, die beliebte Erweiterungen abdecken:
  - **ControlNet** (8 Muster): Modellladen, Vorverarbeitung, Bildgr√∂√üe
  - **LoRA** (6 Muster): Ladefehler, Kompatibilit√§t, Gewichtungsprobleme
  - **VAE** (5 Muster): Kodierungs-/Dekodierungsfehler, Pr√§zision, Tiling
  - **AnimateDiff** (4 Muster): Modellladen, Frame-Anzahl, Kontextl√§nge
  - **IPAdapter** (4 Muster): Modellladen, Bildkodierung, Kompatibilit√§t
  - **FaceRestore** (3 Muster): CodeFormer/GFPGAN-Modelle, Erkennung
  - **Sonstiges** (5 Muster): Checkpoints, Sampler, Scheduler, CLIP
- Vollst√§ndige i18n-Unterst√ºtzung f√ºr Englisch, Traditionelles Chinesisch und Vereinfachtes Chinesisch
- Gesamt: **57 Fehlermuster** (22 integriert + 35 Community)

**Vorteile**:

- ‚úÖ Umfassendere Fehlerabdeckung
- ‚úÖ Hot-Reload von Mustern ohne Neustart von ComfyUI
- ‚úÖ Community kann Muster √ºber JSON-Dateien beisteuern
- ‚úÖ Sauberere, wartbare Codebasis

</details>

<details>
<summary><strong>Fr√ºhere Updates (Dez 2025)</strong></summary>

### F9: Erweiterung der Mehrsprachenunterst√ºtzung

Wir haben die Sprachunterst√ºtzung von 4 auf 9 Sprachen erweitert! ComfyUI-Doctor bietet jetzt Fehlervorschl√§ge in:

- **English** Englisch (en)
- **ÁπÅÈ´î‰∏≠Êñá** Traditionelles Chinesisch (zh_TW)
- **ÁÆÄ‰Ωì‰∏≠Êñá** Vereinfachtes Chinesisch (zh_CN)
- **Êó•Êú¨Ë™û** Japanisch (ja)
- **üÜï Deutsch** (de)
- **üÜï Fran√ßais** Franz√∂sisch (fr)
- **üÜï Italiano** Italienisch (it)
- **üÜï Espa√±ol** Spanisch (es)
- **üÜï ÌïúÍµ≠Ïñ¥** Koreanisch (ko)

Alle 57 Fehlermuster sind vollst√§ndig in alle Sprachen √ºbersetzt, was eine konsistente Diagnosequalit√§t weltweit gew√§hrleistet.

### F8: Integration der Seitenleisteneinstellungen

Die Einstellungen wurden optimiert! Konfigurieren Sie Doctor direkt √ºber die Seitenleiste:

- Klicken Sie auf das ‚öôÔ∏è-Symbol im Seitenleisten-Header, um auf alle Einstellungen zuzugreifen
- Sprachauswahl (9 Sprachen)
- KI-Anbieter Schnellumschaltung (OpenAI, DeepSeek, Groq, Gemini, Ollama usw.)
- Automatische Basis-URL-Eingabe beim Anbieterwechsel
- API-Schl√ºsselverwaltung (passwortgesch√ºtzte Eingabe)
- Konfiguration des Modellnamens
- Einstellungen werden sitzungs√ºbergreifend mit localStorage gespeichert
- Visuelles Feedback beim Speichern (‚úÖ Gespeichert! / ‚ùå Fehler)

Das ComfyUI-Einstellungsfeld zeigt jetzt nur noch den Aktivieren/Deaktivieren-Schalter an ‚Äì alle anderen Einstellungen wurden f√ºr eine sauberere, integrierte Erfahrung in die Seitenleiste verschoben.

</details>

---

## Funktionen

- **Automatische Fehler√ºberwachung**: Erfasst alle Terminalausgaben und erkennt Python-Tracebacks in Echtzeit
- **Intelligente Fehleranalyse**: 57+ Fehlermuster (22 integriert + 35 Community) mit umsetzbaren Vorschl√§gen
- **Knoten-Kontext-Extraktion**: Identifiziert, welcher Knoten den Fehler verursacht hat (Knoten-ID, Name, Klasse)
- **Systemumgebungs-Kontext**: Integriert automatisch Python-Version, installierte Pakete (pip list) und OS-Infos in die KI-Analyse
- **Mehrsprachenunterst√ºtzung**: 9 unterst√ºtzte Sprachen (Englisch, Traditionelles Chinesisch, Vereinfachtes Chinesisch, Japanisch, Deutsch, Franz√∂sisch, Italienisch, Spanisch, Koreanisch)
- **JSON-basiertes Mustermanagement**: Hot-Reload von Fehlermustern ohne Neustart von ComfyUI
- **Community-Muster-Support**: Deckt ControlNet, LoRA, VAE, AnimateDiff, IPAdapter, FaceRestore und mehr ab
- **Debug-Inspektor-Knoten**: Tiefe Inspektion von Daten, die durch Ihren Workflow flie√üen
- **Fehlerverlauf**: H√§lt einen Puffer der letzten Fehler √ºber die API bereit
- **RESTful API**: Sieben Endpunkte f√ºr die Frontend-Integration
- **KI-gest√ºtzte Analyse**: Ein-Klick-LLM-Fehleranalyse mit Unterst√ºtzung f√ºr 8+ Anbieter (OpenAI, DeepSeek, Groq, Gemini, Ollama, LMStudio und mehr)
- **Interaktive Chat-Schnittstelle**: Multi-Turn-KI-Debugging-Assistent, integriert in die ComfyUI-Seitenleiste
- **Interaktive Seitenleisten-UI**: Visuelles Fehlerpanel mit Knotenlokalisierung und Sofortdiagnose
- **Flexible Konfiguration**: Umfassendes Einstellungsfeld zur Anpassung des Verhaltens

### üÜï KI-Chat-Schnittstelle

Die neue interaktive Chat-Schnittstelle bietet ein gespr√§chsbasiertes Debugging-Erlebnis direkt in der linken Seitenleiste von ComfyUI. Wenn ein Fehler auftritt, klicken Sie einfach auf "Analyze with AI", um eine Multi-Turn-Konversation mit Ihrem bevorzugten LLM zu beginnen.

<div align="center">
<img src="../../assets/chat-ui.png" alt="AI Chat Interface">
</div>

**Hauptmerkmale:**

- **Kontext-bewusst**: F√ºgt Fehlerdetails, Knoteninformationen und Workflow-Kontext automatisch hinzu
- **Umgebungs-bewusst**: Beinhaltet Python-Version, installierte Pakete und OS-Infos f√ºr genaues Debugging
- **Streaming-Antworten**: Echtzeit-LLM-Antworten mit korrekter Formatierung
- **Multi-Turn-Konversationen**: Stellen Sie Folgefragen, um Problemen auf den Grund zu gehen
- **Immer zug√§nglich**: Der Eingabebereich bleibt unten sichtbar (Sticky Positioning)
- **Unterst√ºtzt 8+ LLM-Anbieter**: OpenAI, DeepSeek, Groq, Gemini, Ollama, LMStudio und mehr
- **Intelligentes Caching**: Paketliste wird f√ºr 24 Stunden zwischengespeichert, um Auswirkungen auf die Leistung zu vermeiden

**Verwendung:**

1. Wenn ein Fehler auftritt, √∂ffnen Sie die Doctor-Seitenleiste (linkes Panel)
2. Klicken Sie im Fehlerkontextbereich auf die Schaltfl√§che "‚ú® Analyze with AI"
3. Die KI analysiert den Fehler automatisch und liefert Vorschl√§ge
4. Setzen Sie das Gespr√§ch fort, indem Sie Folgefragen in das Eingabefeld eingeben
5. Dr√ºcken Sie Enter oder klicken Sie auf "Send", um Ihre Nachricht abzusenden

> **üí° Kostenloser API-Tipp**: [Google AI Studio](https://aistudio.google.com/app/apikey) (Gemini) bietet eine gro√üz√ºgige kostenlose Stufe ohne Kreditkarte an. Perfekt, um ohne Kosten mit KI-gest√ºtztem Debugging zu beginnen!

---

## Installation

### Option 1: ComfyUI-Manager verwenden (Empfohlen)

1. √ñffnen Sie ComfyUI und klicken Sie im Men√º auf die Schaltfl√§che **Manager**
2. W√§hlen Sie **Install Custom Nodes**
3. Suchen Sie nach `ComfyUI-Doctor`
4. Klicken Sie auf **Install** und starten Sie ComfyUI neu

### Option 2: Manuelle Installation (Git Clone)

1. Navigieren Sie zu Ihrem ComfyUI-Verzeichnis f√ºr benutzerdefinierte Knoten:

   ```bash
   cd ComfyUI/custom_nodes/
   ```

2. Klonen Sie dieses Repository:

   ```bash
   git clone https://github.com/rookiestar28/ComfyUI-Doctor.git
   ```

3. Starten Sie ComfyUI neu

4. Achten Sie in der Konsole auf die Initialisierungsnachricht:

   ```text
   [ComfyUI-Doctor] Initializing Smart Debugger...
   [ComfyUI-Doctor] Log file: .../logs/comfyui_debug_2025-12-28.log
   
   ==================== SYSTEM SNAPSHOT ====================
   OS: Windows 11
   Python: 3.12.3
   PyTorch: 2.0.1+cu118
   CUDA Available: True
   ...
   ```

---

## Verwendung

### Passiver Modus (Automatisch)

Nach der Installation f√ºhrt ComfyUI-Doctor automatisch Folgendes aus:

- Zeichnet alle Konsolenausgaben im Verzeichnis `logs/` auf
- Erkennt Fehler und liefert Vorschl√§ge
- Protokolliert Systemumgebungsinformationen

**Beispiel Fehler-Output**:

```
Traceback (most recent call last):
  ...
RuntimeError: CUDA out of memory. Tried to allocate 2.00 GiB

----------------------------------------
ERROR LOCATION: Node ID: #42 | Name: KSampler
SUGGESTION: OOM (Out Of Memory): Ihr GPU-VRAM ist voll. Versuchen Sie:
   1. Batch-Gr√∂√üe reduzieren
   2. '--lowvram' Flag verwenden
   3. Andere GPU-Apps schlie√üen
----------------------------------------
```

### Aktiver Modus (Debug-Knoten)

1. Rechtsklick auf den Canvas ‚Üí `Add Node` ‚Üí `Smart Debug Node`
2. Verbinden Sie den Knoten inline mit einer beliebigen Verbindung (unterst√ºtzt Wildcard-Eingabe `*`)
3. F√ºhren Sie Ihren Workflow aus

**Beispiel-Output**:

```text
[DEBUG] Data Inspection:
  Type: Tensor
  Shape: torch.Size([1, 4, 64, 64])
  Dtype: torch.float16
  Device: cuda:0
  Stats (All): Min=-3.2156, Max=4.8912, Mean=0.0023
```

Der Knoten leitet Daten weiter, ohne die Workflow-Ausf√ºhrung zu beeintr√§chtigen.

---

## Frontend-UI

ComfyUI-Doctor bietet eine interaktive Seitenleisten-Schnittstelle f√ºr Echtzeit-Fehler√ºberwachung und Diagnose.

### Zugriff auf das Doctor-Panel

Klicken Sie im ComfyUI-Men√º (linke Seitenleiste) auf die Schaltfl√§che **üè• Doctor**, um das Doctor-Panel zu √∂ffnen. Das Panel wird von der rechten Seite des Bildschirms eingeblendet.

### Schnittstellenfunktionen

<div align="center">
<img src="../../assets/doctor-side-bar.png" alt="Error Report">
</div>

Die Doctor-Schnittstelle besteht aus zwei Panels:

#### Linkes Seitenleistenpanel (Doctor-Seitenleiste)

Klicken Sie auf das **üè• Doctor**-Symbol im linken ComfyUI-Men√º, um darauf zuzugreifen:

- **Einstellungsfeld** (‚öôÔ∏è-Symbol): Konfigurieren Sie Sprache, KI-Anbieter, API-Schl√ºssel und Modellauswahl
- **Fehlerkontextkarte**: Wenn ein Fehler auftritt, wird Folgendes angezeigt:
  - **üí° Vorschlag**: Pr√§gnanter, umsetzbarer Rat (z. B. "√úberpr√ºfen Sie die Eingabeverbindungen...")
  - **Zeitstempel**: Wann der Fehler aufgetreten ist
  - **Knotenkontext**: Knoten-ID und Name (falls zutreffend)
  - **‚ú® Analyze with AI**: Starten Sie interaktiven Chat f√ºr detailliertes Debugging
- **KI-Chat-Schnittstelle**: Multi-Turn-Konversation mit Ihrem LLM f√ºr eingehende Fehleranalysen
- **Sticky Eingabebereich**: Immer unten zug√§nglich f√ºr Folgefragen

#### Rechtes Fehlerpanel (Neueste Diagnose)

Echtzeit-Fehlerbenachrichtigungen in der oberen rechten Ecke:

![Doctor Error Report](../../assets/error-report.png)

- **Statusanzeige**: Farbiger Punkt zeigt den Systemzustand an
  - üü¢ **Gr√ºn**: System l√§uft normal, keine Fehler erkannt
  - üî¥ **Rot (pulsierend)**: Aktiver Fehler erkannt
- **Karte der neuesten Diagnose**: Zeigt den aktuellsten Fehler an mit:
  - **Fehlerzusammenfassung**: Kurze Fehlerbeschreibung (rotes Thema, f√ºr lange Fehler einklappbar)
  - **üí° Vorschlag**: Pr√§gnanter, umsetzbarer Rat (gr√ºnes Thema)
  - **Zeitstempel**: Wann der Fehler aufgetreten ist
  - **Knotenkontext**: Knoten-ID, Name und Klasse
  - **üîç Knoten auf Canvas lokalisieren**: Zentriert den problematischen Knoten automatisch und hebt ihn hervor

**Wichtige Designprinzipien**:

- ‚úÖ **Pr√§gnante Vorschl√§ge**: Nur der umsetzbare Rat wird angezeigt (z. B. "√úberpr√ºfen Sie Eingabeverbindungen...") anstatt ausf√ºhrlicher Fehlerbeschreibungen
- ‚úÖ **Visuelle Trennung**: Fehlermeldungen (rot) und Vorschl√§ge (gr√ºn) werden klar unterschieden
- ‚úÖ **Intelligente K√ºrzung**: Lange Fehler zeigen die ersten 3 + letzten 3 Zeilen mit einklappbaren vollst√§ndigen Details
- ‚úÖ **Echtzeit-Updates**: Beide Panels werden automatisch aktualisiert, wenn neue Fehler √ºber WebSocket-Ereignisse auftreten

---

## KI-gest√ºtzte Fehleranalyse

ComfyUI-Doctor integriert sich in beliebte LLM-Dienste, um intelligente, kontextbewusste Debugging-Vorschl√§ge bereitzustellen.

### Unterst√ºtzte KI-Anbieter

#### Cloud-Dienste

- **OpenAI** (GPT-4, GPT-4o usw.)
- **DeepSeek** (DeepSeek-V2, DeepSeek-Coder)
- **Groq Cloud** (Llama 3, Mixtral - ultraschnelle LPU-Inferenz)
- **Google Gemini** (Gemini Pro, Gemini Flash)
- **xAI Grok** (Grok-2, Grok-beta)
- **OpenRouter** (Zugriff auf Claude, GPT-4 und 100+ Modelle)

#### Lokale Dienste (Kein API-Schl√ºssel erforderlich)

- **Ollama** (`http://127.0.0.1:11434`) - Llama, Mistral, CodeLlama lokal ausf√ºhren
- **LMStudio** (`http://localhost:1234/v1`) - Lokale Modellinferenz mit GUI

> **üí° Plattform√ºbergreifende Kompatibilit√§t**: Standard-URLs k√∂nnen √ºber Umgebungsvariablen √ºberschrieben werden:
>
> - `OLLAMA_BASE_URL` - Benutzerdefinierter Ollama-Endpunkt (Standard: `http://127.0.0.1:11434`)
> - `LMSTUDIO_BASE_URL` - Benutzerdefinierter LMStudio-Endpunkt (Standard: `http://localhost:1234/v1`)
>
> Dies verhindert Konflikte zwischen Windows- und WSL2-Ollama-Instanzen oder beim Ausf√ºhren in Docker/benutzerdefinierten Setups.

### Konfiguration

![Einstellungsfeld](../../assets/settings.png)

Konfigurieren Sie die KI-Analyse im Panel **Doctor-Seitenleiste** ‚Üí **Settings**:

1. **KI-Anbieter**: W√§hlen Sie aus dem Dropdown-Men√º. Die Basis-URL wird automatisch ausgef√ºllt.
2. **KI-Basis-URL**: Der API-Endpunkt (automatisch ausgef√ºllt, aber anpassbar)
3. **KI-API-Schl√ºssel**: Ihr API-Schl√ºssel (leer lassen f√ºr lokale LLMs wie Ollama/LMStudio)
4. **KI-Modellname**:
   - W√§hlen Sie ein Modell aus der Dropdown-Liste (automatisch von der API Ihres Anbieters ausgef√ºllt)
   - Klicken Sie auf die üîÑ Aktualisieren-Schaltfl√§che, um verf√ºgbare Modelle neu zu laden
   - Oder aktivieren Sie "Modellnamen manuell eingeben", um einen benutzerdefinierten Modellnamen einzugeben
5. **Datenschutzmodus**: W√§hlen Sie die PII-Bereinigungsstufe f√ºr Cloud-KI-Dienste (siehe Abschnitt [Datenschutzmodus (PII-Bereinigung)](#datenschutzmodus-pii-bereinigung) unten f√ºr Details)

### Verwendung der KI-Analyse

1. Das Doctor-Panel √∂ffnet sich automatisch, wenn ein Fehler auftritt.
2. √úberpr√ºfen Sie die integrierten Vorschl√§ge oder klicken Sie auf die Schaltfl√§che ‚ú® Analyze with AI auf der Fehlerkarte.
3. Warten Sie, bis das LLM den Fehler analysiert hat (typischerweise 3-10 Sekunden).
4. √úberpr√ºfen Sie die KI-generierten Debugging-Vorschl√§ge.

**Sicherheitshinweis**: Ihr API-Schl√ºssel wird nur f√ºr die Analyseanfrage sicher vom Frontend zum Backend √ºbertragen. Er wird niemals protokolliert oder dauerhaft gespeichert.

### Datenschutzmodus (PII-Bereinigung)

ComfyUI-Doctor enth√§lt eine automatische **PII (Personally Identifiable Information) Bereinigung**, um Ihre Privatsph√§re beim Senden von Fehlermeldungen an Cloud-KI-Dienste zu sch√ºtzen.

**Drei Datenschutzstufen**:

| Stufe | Beschreibung | Was entfernt wird | Empfohlen f√ºr |
| ----- | ----------- | --------------- | --------------- |
| **None** | Keine Bereinigung | Nichts | Lokale LLMs (Ollama, LMStudio) |
| **Basic** (Standard) | Standardschutz | Benutzerpfade, API-Schl√ºssel, E-Mails, IP-Adressen | Die meisten Benutzer mit Cloud-LLMs |
| **Strict** | Maximaler Datenschutz | Alles von Basic + IPv6, SSH-Fingerabdr√ºcke | Enterprise/Compliance-Anforderungen |

**Was bereinigt wird** (Basic-Stufe):

- ‚úÖ Windows-Benutzerpfade: `C:\Users\john\file.py` ‚Üí `<USER_PATH>\file.py`
- ‚úÖ Linux/macOS-Home: `/home/alice/test.py` ‚Üí `<USER_HOME>/test.py`
- ‚úÖ API-Schl√ºssel: `sk-abc123...` ‚Üí `<API_KEY>`
- ‚úÖ E-Mail-Adressen: `user@example.com` ‚Üí `<EMAIL>`
- ‚úÖ Private IPs: `192.168.1.1` ‚Üí `<PRIVATE_IP>`
- ‚úÖ URL-Anmeldeinformationen: `https://user:pass@host` ‚Üí `https://<USER>@host`

**Was NICHT entfernt wird**:

- ‚ùå Fehlermeldungen (f√ºr Debugging ben√∂tigt)
- ‚ùå Modellnamen, Knotennamen
- ‚ùå Workflow-Struktur
- ‚ùå √ñffentliche Dateipfade (`/usr/bin/python`)

**Datenschutzmodus konfigurieren**: Doctor-Seitenleiste √∂ffnen ‚Üí Settings ‚Üí üîí Privacy Mode Dropdown. √Ñnderungen gelten sofort f√ºr alle KI-Analyseanfragen.

**DSGVO-Konformit√§t**: Diese Funktion unterst√ºtzt DSGVO Artikel 25 (Datenschutz durch Technikgestaltung) und wird f√ºr Enterprise-Bereitstellungen empfohlen.

### Statistik-Dashboard

![Statistik-Panel](../../assets/statistics_panel.png)

Das **Statistik-Dashboard** bietet Echtzeit-Einblicke in Ihre ComfyUI-Fehlermuster und Stabilit√§tstrends.

**Funktionen**:

- **üìä Fehlertrends**: Gesamtfehler und Z√§hlungen f√ºr die letzten 24 Std./7 Tage/30 Tage
- **üî• Top-Fehlermuster**: Top 5 der h√§ufigsten Fehlertypen mit Vorkommensanzahl
- **üìà Kategorie-Aufschl√ºsselung**: Visuelle Aufschl√ºsselung nach Fehlerkategorie (Speicher, Workflow, Modellladen, Framework, Generisch)
- **‚úÖ L√∂sungsverfolgung**: Verfolgen Sie gel√∂ste, ungel√∂ste und ignorierte Fehler
- **üß≠ Status-Steuerung**: Den neuesten Fehler im Statistik-Tab als Gel√∂st / Ungel√∂st / Ignoriert markieren
- **üõ°Ô∏è Vertrauen & Gesundheit (Trust & Health)**: `/doctor/health` Metriken und Plugin-Vertrauensbericht anzeigen (nur Scan)
- **üìä Anonyme Telemetrie (Anonymous Telemetry) (Im Aufbau üöß)**: Opt-in lokaler Puffer f√ºr Nutzungsereignisse (Umschalten/Anzeigen/L√∂schen/Exportieren)

**Verwendung**:

1. Doctor-Seitenleiste √∂ffnen (üè•-Symbol links klicken)
2. Den einklappbaren Abschnitt **üìä Fehlerstatistik** finden
3. Klicken zum Erweitern und Anzeigen Ihrer Fehleranalysen
4. Mit den **Mark as**-Schaltfl√§chen den Status des neuesten Fehlers setzen (Gel√∂st / Ungel√∂st / Ignoriert)
5. Scrollen Sie zum Ende des Statistik-Tabs, um **Vertrauen & Gesundheit** und **Anonyme Telemetrie** zu finden.

**Steuerung des L√∂sungsstatus**:

- Schaltfl√§chen sind nur aktiv, wenn ein Zeitstempel f√ºr den neuesten Fehler verf√ºgbar ist
- Status-Updates werden in der Historie gespeichert und aktualisieren die L√∂sungsquote automatisch

**Verst√§ndnis der Daten**:

- **Total (30d)**: Kumulative Fehler in den letzten 30 Tagen
- **Last 24h**: Fehler in den letzten 24 Stunden (hilft bei der Identifizierung aktueller Probleme)
- **Resolution Rate (L√∂sungsquote)**: Zeigt den Fortschritt bei der L√∂sung bekannter Probleme
  - üü¢ **Gel√∂st**: Probleme, die Sie behoben haben
  - üü† **Ungel√∂st**: Aktive Probleme, die Aufmerksamkeit erfordern
  - ‚ö™ **Ignoriert**: Unkritische Probleme, die Sie ignorieren
- **Top Patterns**: Identifiziert, welche Fehlertypen priorisierte Aufmerksamkeit ben√∂tigen
- **Categories**: Hilft Ihnen zu verstehen, ob Probleme speicherbezogen, Workflow-Probleme, Modellladefehler usw. sind

**Panel-Status-Persistenz**: Der Status "ge√∂ffnet/geschlossen" des Panels wird im localStorage Ihres Browsers gespeichert, sodass Ihre Pr√§ferenz sitzungs√ºbergreifend erhalten bleibt.

### Beispiel Provider-Setup

| Anbieter         | Basis-URL                                                  | Modell-Beispiel              |
|------------------|------------------------------------------------------------|------------------------------|
| OpenAI           | `https://api.openai.com/v1`                                | `gpt-4o`                     |
| DeepSeek         | `https://api.deepseek.com/v1`                              | `deepseek-chat`              |
| Groq             | `https://api.groq.com/openai/v1`                           | `llama-3.1-70b-versatile`    |
| Gemini           | `https://generativelanguage.googleapis.com/v1beta/openai`  | `gemini-1.5-flash`           |
| Ollama (Lokal)   | `http://localhost:11434/v1`                                | `llama3.1:8b`                |
| LMStudio (Lokal) | `http://localhost:1234/v1`                                 | In LMStudio geladenes Modell |

---

## Einstellungen

You can also customize ComfyUI-Doctor behavior via the **Doctor sidebar ‚Üí Settings** tab.

### 1. Show error notifications (Fehlerbenachrichtigungen anzeigen)

**Funktion**: Schaltet schwebende Fehlerbenachrichtigungskarten (Toasts) in der oberen rechten Ecke um.
**Verwendung**: Deaktivieren, wenn Sie Fehler lieber manuell in der Seitenleiste ohne visuelle Unterbrechungen √ºberpr√ºfen m√∂chten.

### 2. Auto-open panel on error (Panel bei Fehler automatisch √∂ffnen)

**Function**: Automatically opens the **right-side error report panel** when a new error is detected.
**Usage**: **Default: ON**. Disable if you prefer to keep the panel closed and open it manually.

### 3. Error Check Interval (ms)

**Funktion**: H√§ufigkeit der Frontend-Backend-Fehlerpr√ºfungen (in Millisekunden). Standard: `2000`.
**Verwendung**: Niedrigere Werte (z. B. 500) geben schnelleres Feedback, erh√∂hen aber die Last; h√∂here Werte (z. B. 5000) sparen Ressourcen.

### 4. Suggestion Language (Vorschlagssprache)

**Funktion**: Sprache f√ºr Diagnoseberichte und Doctor-Vorschl√§ge.
**Verwendung**: Unterst√ºtzt derzeit Englisch, Traditionelles Chinesisch, Vereinfachtes Chinesisch, Japanisch (weitere folgen bald). √Ñnderungen gelten f√ºr neue Fehler.

### 5. Enable Doctor (requires restart)

**Funktion**: Hauptschalter f√ºr das Log-Abfangsystem.
**Verwendung**: Ausschalten, um die Kernfunktionalit√§t von Doctor vollst√§ndig zu deaktivieren (erfordert ComfyUI-Neustart).

### 6. AI Provider

**Funktion**: W√§hlen Sie Ihren bevorzugten LLM-Dienstanbieter aus einem Dropdown-Men√º.
**Optionen**: OpenAI, DeepSeek, Groq Cloud, Google Gemini, xAI Grok, OpenRouter, Ollama (Lokal), LMStudio (Lokal), Benutzerdefiniert.
**Verwendung**: Durch Auswahl eines Anbieters wird die entsprechende Basis-URL automatisch ausgef√ºllt. F√ºr lokale Anbieter (Ollama/LMStudio) zeigt ein Alarm verf√ºgbare Modelle an.

### 7. AI Base URL

**Funktion**: Der API-Endpunkt f√ºr Ihren LLM-Dienst.
**Verwendung**: Automatisch ausgef√ºllt, wenn Sie einen Anbieter ausw√§hlen, kann aber f√ºr selbst gehostete oder benutzerdefinierte Endpunkte angepasst werden.

### 8. AI API Key

**Funktion**: Ihr API-Schl√ºssel zur Authentifizierung bei Cloud-LLM-Diensten.
**Verwendung**: Erforderlich f√ºr Cloud-Anbieter (OpenAI, DeepSeek usw.). Leer lassen f√ºr lokale LLMs (Ollama, LMStudio).
**Sicherheit**: Der Schl√ºssel wird nur w√§hrend der Analyseanfragen √ºbertragen und niemals protokolliert oder dauerhaft gespeichert.

### 9. AI Model Name

**Funktion**: Geben Sie an, welches Modell f√ºr die Fehleranalyse verwendet werden soll.
**Verwendung**:

- **Dropdown-Modus** (Standard): W√§hlen Sie ein Modell aus der automatisch ausgef√ºllten Dropdown-Liste. Klicken Sie auf die üîÑ Aktualisieren-Schaltfl√§che, um verf√ºgbare Modelle neu zu laden.
- **Manueller Eingabemodus**: Aktivieren Sie "Modellnamen manuell eingeben", um einen benutzerdefinierten Modellnamen einzugeben (z. B. `gpt-4o`, `deepseek-chat`, `llama3.1:8b`).
- Modelle werden automatisch von der API Ihres ausgew√§hlten Anbieters abgerufen, wenn Sie den Anbieter √§ndern oder auf Aktualisieren klicken.
- F√ºr lokale LLMs (Ollama/LMStudio) zeigt das Dropdown alle lokal verf√ºgbaren Modelle an.

> Hinweis: **Vertrauen & Gesundheit (Trust & Health)** und **Anonyme Telemetrie (Anonymous Telemetry)** wurden in den **Statistik (Statistics)** Tab verschoben.

> Hinweis: **F14 Proaktive Diagnose (Proactive Diagnostics)** ist √ºber den Tab **Statistik (Statistics)** ‚Üí Bereich **Diagnose (Diagnostics)** zug√§nglich.
> Verwenden Sie **Run / Refresh**, um einen Bericht zu erstellen, die Problemliste anzuzeigen und die bereitgestellten Aktionen (z. B. Knoten lokalisieren) zu nutzen.
> Wenn Sie den Bericht in einer anderen Sprache anzeigen m√ºssen, √§ndern Sie zuerst die **Suggestion Language** in den Einstellungen.

---

## API-Endpunkte

### GET `/debugger/last_analysis`

Die letzte Fehleranalyse abrufen:

```bash
curl http://localhost:8188/debugger/last_analysis
```

**Antwort-Beispiel**:

```json
{
  "status": "running",
  "log_path": ".../logs/comfyui_debug_2025-12-28.log",
  "language": "zh_TW",
  "supported_languages": ["en", "zh_TW", "zh_CN", "ja"],
  "last_error": "Traceback...",
  "suggestion": "SUGGESTION: ...",
  "timestamp": "2025-12-28T06:49:11",
  "node_context": {
    "node_id": "42",
    "node_name": "KSampler",
    "node_class": "KSamplerNode",
    "custom_node_path": "ComfyUI-Impact-Pack"
  }
}
```

### GET `/debugger/history`

Fehlerverlauf abrufen (letzte 20 Eintr√§ge):

```bash
curl http://localhost:8188/debugger/history
```

### POST `/debugger/set_language`

Die Vorschlagssprache √§ndern (siehe Abschnitt Sprachumschaltung).

### POST `/doctor/analyze`

Einen Fehler mit dem konfigurierten LLM-Dienst analysieren.

**Payload**:

```json
{
  "error": "Traceback...",
  "node_context": {...},
  "api_key": "your-api-key",
  "base_url": "https://api.openai.com/v1",
  "model": "gpt-4o",
  "language": "en"
}
```

**Antwort**:

```json
{
  "analysis": "AI-generated debugging suggestions..."
}
```

### POST `/doctor/verify_key`

API-Schl√ºsselg√ºltigkeit durch Testen der Verbindung zum LLM-Anbieter √ºberpr√ºfen.

**Payload**:

```json
{
  "base_url": "https://api.openai.com/v1",
  "api_key": "your-api-key"
}
```

**Antwort**:

```json
{
  "success": true,
  "message": "API key is valid",
  "is_local": false
}
```

### POST `/doctor/list_models`

Verf√ºgbare Modelle vom konfigurierten LLM-Anbieter auflisten.

**Payload**:

```json
{
  "base_url": "http://localhost:11434/v1",
  "api_key": ""
}
```

**Antwort**:

```json
{
  "success": true,
  "models": [
    {"id": "llama3.1:8b", "name": "llama3.1:8b"},
    {"id": "mistral:7b", "name": "mistral:7b"}
  ],
  "message": "Found 2 models"
}
```

---

## Log-Dateien

Alle Logs werden gespeichert in:

```text
ComfyUI/custom_nodes/ComfyUI-Doctor/logs/
```

Dateinamenformat: `comfyui_debug_YYYY-MM-DD_HH-MM-SS.log`

Das System beh√§lt automatisch die 10 neuesten Log-Dateien (konfigurierbar √ºber `config.json`).

---

## Konfiguration

Erstellen Sie `config.json`, um das Verhalten anzupassen:

```json
{
  "max_log_files": 10,
  "buffer_limit": 100,
  "traceback_timeout_seconds": 5.0,
  "history_size": 20,
  "default_language": "zh_TW",
  "enable_api": true,
  "privacy_mode": "basic"
}
```

**Parameter**:

- `max_log_files`: Maximale Anzahl der zu behaltenden Log-Dateien
- `buffer_limit`: Traceback-Puffergr√∂√üe (Zeilenanzahl)
- `traceback_timeout_seconds`: Timeout f√ºr unvollst√§ndige Tracebacks
- `history_size`: Anzahl der Fehler im Verlauf
- `default_language`: Standardsprache f√ºr Vorschl√§ge
- `enable_api`: API-Endpunkte aktivieren
- `privacy_mode`: PII-Beschr√§nkungsstufe - `"none"`, `"basic"` (Standard) oder `"strict"`

---

## Unterst√ºtzte Fehlermuster

ComfyUI-Doctor kann erkennen und Vorschl√§ge liefern f√ºr:

- Typkonflikte (z. B. fp16 vs float32)
- Dimensionskonflikte
- CUDA/MPS Speicher knapp (OOM)
- Matrixmultiplikationsfehler
- Ger√§te-/Typkonflikte
- Fehlende Python-Module
- Assertionsfehler
- Schl√ºssel-/Attributfehler
- Formkonflikte (Shape Mismatches)
- Datei-nicht-gefunden-Fehler
- SafeTensors-Ladefehler
- CUDNN-Ausf√ºhrungsfehler
- Fehlende InsightFace-Bibliothek
- Modell/VAE-Nicht√ºbereinstimmungen
- Ung√ºltiges Prompt-JSON

Und mehr...

---

## Tipps

1. **Mit ComfyUI Manager koppeln**: Fehlende benutzerdefinierte Knoten automatisch installieren
2. **Log-Dateien pr√ºfen**: Vollst√§ndige Tracebacks werden f√ºr die Fehlerberichterstattung aufgezeichnet
3. **Integrierte Seitenleiste verwenden**: Klicken Sie auf das üè• Doctor-Symbol im linken Men√º f√ºr Echtzeit-Diagnosen
4. **Knoten-Debugging**: Debug-Knoten verbinden, um verd√§chtigen Datenfluss zu inspizieren

---

## Lizenz

MIT License

---

## Mitwirken

Beitr√§ge sind willkommen! F√ºhlen Sie sich frei, einen Pull Request einzureichen.

**Probleme melden**: Einen Fehler gefunden oder einen Vorschlag? Er√∂ffnen Sie ein Issue auf GitHub.
**PRs einreichen**: Helfen Sie, die Codebasis mit Fehlerbehebungen oder allgemeinen Verbesserungen zu optimieren.
**Feature-Anfragen**: Haben Sie Ideen f√ºr neue Funktionen? Lassen Sie es uns bitte wissen.
